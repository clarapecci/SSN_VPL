{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d354ebc",
   "metadata": {},
   "source": [
    "# 2D SSN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74304b9",
   "metadata": {},
   "source": [
    "Information on training vmap:\n",
    "- https://jax.readthedocs.io/en/latest/_autosummary/jax.vmap.html\n",
    "- https://jax.readthedocs.io/en/latest/notebooks/Neural_Network_and_Data_Loading.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adb6de8",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4d27bfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time, os, json\n",
    "import pandas as pd\n",
    "from scipy import stats \n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import jax\n",
    "from jax import random\n",
    "from jax.config import config \n",
    "import jax.numpy as np\n",
    "from jax import vmap\n",
    "import pdb\n",
    "import optax\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "#config.update('jax_debug_nans', True)\n",
    "from SSN_classes_jax import SSN2DTopoV1_AMPAGABA_ONOFF\n",
    "from util import GaborFilter, BW_Grating, find_A, create_gabor_filters, create_gratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993dd69f",
   "metadata": {},
   "source": [
    "## GENERATE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2bbddbd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 50)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gabor parameters \n",
    "sigma_g= 0.5\n",
    "k = np.pi/(6*sigma_g)\n",
    "\n",
    "#Parameters shared with stimuli\n",
    "general_pars = dict(k=k , edge_deg=3.2,  degree_per_pixel=0.05)\n",
    "\n",
    "#Stimuli parameters\n",
    "stimuli_pars = dict(outer_radius=3, inner_radius=2.5, grating_contrast=0.5, snr = 0.9)\n",
    "stimuli_pars.update(general_pars)\n",
    "\n",
    "#Create gratings at given or ientation and list of labels\n",
    "data = create_gratings(ref_ori=55, number=250, offset= 0.5, jitter_val=5, **stimuli_pars)\n",
    "train, test = train_test_split(data, test_size = 0.2)\n",
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b5da6b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#batch params \n",
    "batch_size= 20\n",
    "train_dataloader =DataLoader(train, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test, batch_size=len(test), shuffle=False)\n",
    "number_batches= int(len(train) / batch_size)\n",
    "number_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844906d1",
   "metadata": {},
   "source": [
    "# MODEL TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8497399e",
   "metadata": {},
   "source": [
    "1. Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3969cb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Network parameters\n",
    "class ssn_pars():\n",
    "    n = 2\n",
    "    k = 0.04\n",
    "    tauE = 30 # in ms\n",
    "    tauI = 10 # in ms\n",
    "    psi = 0.774\n",
    "    tau_s = np.array([5, 7, 100]) #in ms, AMPA, GABA, NMDA current decay time constants\n",
    "    \n",
    "\n",
    "#Grid parameters\n",
    "class grid_pars():\n",
    "    gridsize_Nx = 9 # grid-points across each edge # gives rise to dx = 0.8 mm\n",
    "    gridsize_deg = 2 * 1.6 # edge length in degrees\n",
    "    magnif_factor = 2  # mm/deg\n",
    "    hyper_col = 0.8 # mm   \n",
    "    sigma_RF = 0.4 # deg (visual angle)\n",
    "\n",
    "# Caleb's params for the full (with local) model:\n",
    "Js0 = [1.82650658, 0.68194475, 2.06815311, 0.5106321]\n",
    "gE, gI = 0.57328625, 0.26144141\n",
    "\n",
    "sigEE, sigIE = 0.2, 0.40\n",
    "sigEI, sigII = .09, .09\n",
    "conn_pars = dict(\n",
    "    PERIODIC = False,\n",
    "    p_local = [.4, 0.7], # [p_local_EE, p_local_IE],\n",
    "    sigma_oris = 1000) # sigma_oris\n",
    "\n",
    "\n",
    "make_J2x2 = lambda Jee, Jei, Jie, Jii: np.array([[Jee, -Jei], [Jie,  -Jii]]) * np.pi * ssn_pars.psi\n",
    "J_2x2 = make_J2x2(*Js0)\n",
    "s_2x2 = np.array([[sigEE, sigEI],[sigIE, sigII]])\n",
    "\n",
    "#Positive reparameterization\n",
    "signs=np.array([[1, -1], [1, -1]])\n",
    "logJ_2x2 =np.log(J_2x2*signs)\n",
    "logs_2x2 = np.log(s_2x2)\n",
    "\n",
    "\n",
    "#Sigmoid parameters\n",
    "N_neurons = 25\n",
    "key = random.PRNGKey(60)\n",
    "w_sig = random.normal(key, shape = (N_neurons,)) / np.sqrt(N_neurons)\n",
    "b_sig = 0.0\n",
    "\n",
    "\n",
    "#Optimization pars\n",
    "opt_pars = dict(logJ_2x2 = logJ_2x2, logs_2x2 = logs_2x2, w_sig = w_sig, b_sig=b_sig)\n",
    "\n",
    "\n",
    "#Parameters exclusive to Gabor filters\n",
    "filter_pars = dict(sigma_g = sigma_g, conv_factor = grid_pars.magnif_factor)\n",
    "filter_pars.update(general_pars) \n",
    "\n",
    "#Convergence parameters\n",
    "conv_pars=dict(dt = 1, xtol = 1e-5, Tmax = 200, verbose=False, silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccde2f80",
   "metadata": {},
   "source": [
    "3. TRAINING!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "329c7d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(x))\n",
    "\n",
    "def binary_loss(n, x):\n",
    "    return - (n*np.log(x) + (1-n)*np.log(1-x))\n",
    "\n",
    "def model(opt_pars, ssn_pars, grid_pars, conn_pars, data, filter_pars,  conv_pars):\n",
    "    \n",
    "    signs=np.array([[1, -1], [1, -1]])\n",
    "    \n",
    "    J_2x2 =np.exp(opt_pars['logJ_2x2'])*signs\n",
    "    s_2x2 = np.exp(opt_pars['logs_2x2'])\n",
    "    \n",
    "    total_loss=0\n",
    "    \n",
    "    for i in range(len(data['ref'])):\n",
    "        #Initialise network\n",
    "        ssn=SSN2DTopoV1_AMPAGABA_ONOFF(ssn_pars=ssn_pars, grid_pars=grid_pars, conn_pars=conn_pars, filter_pars=filter_pars, J_2x2=J_2x2, s_2x2=s_2x2)\n",
    "                                                   \n",
    "        #Apply Gabor filters to stimuli\n",
    "        output_ref=np.matmul(ssn.gabor_filters, data['ref'][i])*ssn.A\n",
    "        output_target=np.matmul(ssn.gabor_filters, data['target'][i])*ssn.A\n",
    "\n",
    "        #Rectify output\n",
    "        SSN_input_ref=np.maximum(0, output_ref)\n",
    "        SSN_input_target=np.maximum(0, output_target)\n",
    "        \n",
    "        #Input to SSN\n",
    "        r_init = np.zeros(SSN_input_ref.shape[0])\n",
    "        \n",
    "        fp_ref, _ = ssn.fixed_point_r(SSN_input_ref, r_init=r_init, **conv_pars)\n",
    "        x_ref = ssn.apply_bounding_box(fp_ref, size=3.2)\n",
    "\n",
    "        fp_target, _ = ssn.fixed_point_r(SSN_input_target, r_init=r_init, **conv_pars)\n",
    "        x_target = ssn.apply_bounding_box(fp_target, size=3.2)\n",
    "\n",
    "        #Apply sigmoid function - combine ref and target\n",
    "        x = sigmoid( np.dot(opt_pars['w_sig'], (x_ref.ravel() - x_target.ravel())) + opt_pars['b_sig'])\n",
    "\n",
    "        #Calculate binary cross entropy loss\n",
    "        total_loss+=np.sum(binary_loss(data['label'][i], x))\n",
    "        \n",
    "   \n",
    "    return total_loss\n",
    "    \n",
    "\n",
    "def train_SSN(opt_pars, ssn_pars, grid_pars, conn_pars, train_dataloader, test_dataloader, filter_pars, conv_pars, batches, epochs=1, eta=10e-4):\n",
    "    \n",
    "    #Initialize loss\n",
    "    val_loss_per_epoch = []\n",
    "    \n",
    "    #Initialise optimizer\n",
    "    optimizer = optax.adam(eta)\n",
    "    opt_state = optimizer.init(opt_pars)\n",
    "    \n",
    "    #Define test data - no need to iterate\n",
    "    test_iterator = iter(test_dataloader)\n",
    "    test_data = next(test_iterator)\n",
    "    test_data['ref'] = test_data['ref'].numpy()\n",
    "    test_data['target'] = test_data['target'].numpy()\n",
    "    test_data['label'] = test_data['label'].numpy()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        #Loss and accuracy before training\n",
    "        if epoch == 0:\n",
    "            val_loss= model(opt_pars, ssn_pars, grid_pars, conn_pars, test_data, filter_pars,  conv_pars )\n",
    "            print('Before training  -- loss: {} '.format(val_loss))\n",
    "            val_loss_per_epoch.append(val_loss)\n",
    "\n",
    "        \n",
    "        start_time = time.time()\n",
    "        train_iterator = iter(train_dataloader)\n",
    "        test_iterator = iter(test_dataloader)\n",
    "        \n",
    "        for batch in range(batches):\n",
    "            train_data = next(train_iterator)\n",
    "\n",
    "            train_data['ref'] = train_data['ref'].numpy()\n",
    "            train_data['target'] = train_data['target'].numpy()\n",
    "            train_data['label'] = train_data['label'].numpy()\n",
    "\n",
    "            #compute loss and gradient \n",
    "            grad =jax.grad(model)(opt_pars, ssn_pars, grid_pars, conn_pars, train_data, filter_pars,  conv_pars)\n",
    "\n",
    "            #Apply SGD through Adam optimizer\n",
    "            updates, opt_state = optimizer.update(grad, opt_state)\n",
    "            opt_pars = optax.apply_updates(opt_pars, updates)\n",
    "        \n",
    "        epoch_time =time.time() - start_time\n",
    "    \n",
    "        #Evaluate model\n",
    "        val_loss = model(opt_pars, ssn_pars, grid_pars, conn_pars, test_data, filter_pars,  conv_pars )\n",
    "        print('Validation -- loss: {}, at epoch {}, (time {})'.format(val_loss, epoch+1, epoch_time))\n",
    "        val_loss_per_epoch.append(val_loss)\n",
    "    \n",
    "    \n",
    "    #reparametize parameters\n",
    "    signs=np.array([[1, -1], [1, -1]])    \n",
    "    opt_pars['logJ_2x2'] = np.exp(opt_pars['logJ_2x2'])*signs\n",
    "    opt_pars['logs_2x2'] = np.exp(opt_pars['logs_2x2'])\n",
    "    opt_pars['J_2x2'] = opt_pars['logJ_2x2']\n",
    "    opt_pars['s_2x2'] = opt_pars['logs_2x2']\n",
    "    del opt_pars['logJ_2x2'], opt_pars['logs_2x2']\n",
    "    \n",
    "    return opt_pars, val_loss_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f598922e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_test = model(opt_pars, ssn_pars, grid_pars, conn_pars, gratings, labels, filter_pars,  **conv_pars)\n",
    "new_pars, offset_5_loss= train_SSN(opt_pars, ssn_pars, grid_pars, conn_pars, train_dataloader, test_dataloader, filter_pars, conv_pars, batches = number_batches, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d896f6",
   "metadata": {},
   "source": [
    "# Vmap implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17652a4",
   "metadata": {},
   "source": [
    "Vmap implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "18245873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(x))\n",
    "\n",
    "def binary_loss(n, x):\n",
    "    return - (n*np.log(x) + (1-n)*np.log(1-x))\n",
    "\n",
    "def test_model(opt_pars, ssn_pars, grid_pars, conn_pars, train_data, filter_pars,  conv_pars):\n",
    "    \n",
    "    signs=np.array([[1, -1], [1, -1]])\n",
    "    \n",
    "    J_2x2 =np.exp(opt_pars['logJ_2x2'])*signs\n",
    "    s_2x2 = np.exp(opt_pars['logs_2x2'])\n",
    "    \n",
    "    #Initialise network\n",
    "    ssn=SSN2DTopoV1_AMPAGABA_ONOFF(ssn_pars=ssn_pars, grid_pars=grid_pars, conn_pars=conn_pars, filter_pars=filter_pars, J_2x2=J_2x2, s_2x2=s_2x2)\n",
    "\n",
    "    #Apply Gabor filters to stimuli\n",
    "    output_ref=np.matmul(ssn.gabor_filters, train_data['ref'])*ssn.A\n",
    "    output_target=np.matmul(ssn.gabor_filters, train_data['target'])*ssn.A\n",
    "\n",
    "    #Rectify output\n",
    "    SSN_input_ref=np.maximum(0, output_ref)\n",
    "    SSN_input_target=np.maximum(0, output_target)\n",
    "\n",
    "    #Input to SSN\n",
    "    r_init = np.zeros(SSN_input_ref.shape[0])\n",
    "\n",
    "    fp_ref, _ = ssn.fixed_point_r(SSN_input_ref, r_init=r_init, **conv_pars)\n",
    "    x_ref = ssn.apply_bounding_box(fp_ref, size=3.2)\n",
    "\n",
    "    fp_target, _ = ssn.fixed_point_r(SSN_input_target, r_init=r_init, **conv_pars)\n",
    "    x_target = ssn.apply_bounding_box(fp_target, size=3.2)\n",
    "\n",
    "    #Apply sigmoid function - combine ref and target\n",
    "    x = sigmoid( np.dot(opt_pars['w_sig'], (x_ref.ravel() - x_target.ravel())) + opt_pars['b_sig'])\n",
    "\n",
    "    #Calculate binary cross entropy loss\n",
    "    loss=binary_loss(train_data['label'], x)\n",
    "   \n",
    "    return loss\n",
    "\n",
    "\n",
    "def loss(opt_pars, ssn_pars, grid_pars, conn_pars, train_data, filter_pars,  conv_pars):\n",
    "    '''\n",
    "    Calculate parallelized loss for batch of data through vmap.\n",
    "    Output:\n",
    "        mean loss of all the input images\n",
    "    '''\n",
    "    \n",
    "    vmap_model = vmap(test_model, in_axes = ({'b_sig': None, 'logJ_2x2': None, 'logs_2x2': None, 'w_sig': None}, None, None, {'PERIODIC': None, 'p_local': [None, None], 'sigma_oris': None},  {'ref':0, 'target':0, 'label':0}, {'conv_factor': None, 'degree_per_pixel': None, 'edge_deg': None, 'k': None, 'sigma_g': None}, {'Tmax': None, 'dt': None, 'silent': None, 'verbose': None, 'xtol': None}) )                   \n",
    "    loss = np.sum(vmap_model(opt_pars, ssn_pars, grid_pars, conn_pars, train_data, filter_pars,  conv_pars))\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def train_SSN_vmap(opt_pars, ssn_pars, grid_pars, conn_pars, train_dataloader, test_dataloader, filter_pars, conv_pars, batches, epochs=1, eta=10e-4):\n",
    "    \n",
    "    #Initialize loss\n",
    "    val_loss_per_epoch = []\n",
    "    training_losses=[]\n",
    "    accuracies=[]\n",
    "    \n",
    "    #Initialise optimizer\n",
    "    optimizer = optax.adam(eta)\n",
    "    opt_state = optimizer.init(opt_pars)\n",
    "    \n",
    "    #Define test data - no need to iterate\n",
    "    test_iterator = iter(test_dataloader)\n",
    "    test_data = next(test_iterator)\n",
    "    test_data['ref'] = test_data['ref'].numpy()\n",
    "    test_data['target'] = test_data['target'].numpy()\n",
    "    test_data['label'] = test_data['label'].numpy()\n",
    "    \n",
    "    val_loss, accuracy= vmap_eval(opt_pars, ssn_pars, grid_pars, conn_pars, test_data, filter_pars,  conv_pars)\n",
    "\n",
    "    print('Before training  -- loss: {}, accuracy: {} '.format(val_loss, accuracy))\n",
    "    val_loss_per_epoch.append(val_loss)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        train_iterator = iter(train_dataloader)\n",
    "        epoch_loss = 0 \n",
    "           \n",
    "        #Iterate through data in batches\n",
    "        for batch in range(batches): \n",
    "\n",
    "            #load next batch of data and convert\n",
    "            train_data = next(train_iterator)\n",
    "            #convert tensors to numpy\n",
    "            train_data['ref'] = train_data['ref'].numpy()\n",
    "            train_data['target'] = train_data['target'].numpy()\n",
    "            train_data['label'] = train_data['label'].numpy()\n",
    "            \n",
    "            #Compute loss and gradient\n",
    "            batch_loss, grad =jax.value_and_grad(loss)(opt_pars, ssn_pars, grid_pars, conn_pars, train_data, filter_pars,  conv_pars)\n",
    "            \n",
    "            #Apply SGD through Adam optimizer per batch\n",
    "            updates, opt_state = optimizer.update(grad, opt_state)\n",
    "            opt_pars = optax.apply_updates(opt_pars, updates)\n",
    "            epoch_loss+=batch_loss\n",
    "        \n",
    "        epoch_time = time.time() - start_time\n",
    "        \n",
    "        \n",
    "        #Evaluate model at the end of each epoch\n",
    "        val_loss, accuracy= vmap_eval(opt_pars, ssn_pars, grid_pars, conn_pars, test_data, filter_pars,  conv_pars)\n",
    "        print('Training loss: {} ¦ Validation -- loss: {}, accuracy: {} at epoch {}, (time {})'.format(epoch_loss, val_loss, accuracy, epoch+1, epoch_time))\n",
    "        val_loss_per_epoch.append(val_loss)\n",
    "        training_losses.append(epoch_loss)\n",
    "        accuracies.append(accuracy)\n",
    "    \n",
    "    #reparametize parameters\n",
    "    signs=np.array([[1, -1], [1, -1]])    \n",
    "    opt_pars['logJ_2x2'] = np.exp(opt_pars['logJ_2x2'])*signs\n",
    "    opt_pars['logs_2x2'] = np.exp(opt_pars['logs_2x2'])\n",
    "    \n",
    "    return opt_pars, val_loss_per_epoch, accuracies\n",
    "\n",
    "\n",
    "def eval_model(opt_pars, ssn_pars, grid_pars, conn_pars, test_data, filter_pars,  conv_pars):\n",
    "    signs=np.array([[1, -1], [1, -1]])\n",
    "    \n",
    "    J_2x2 =np.exp(opt_pars['logJ_2x2'])*signs\n",
    "    s_2x2 = np.exp(opt_pars['logs_2x2'])\n",
    "    \n",
    "    #Initialise network\n",
    "    ssn=SSN2DTopoV1_AMPAGABA_ONOFF(ssn_pars=ssn_pars, grid_pars=grid_pars, conn_pars=conn_pars, filter_pars=filter_pars, J_2x2=J_2x2, s_2x2=s_2x2)\n",
    "\n",
    "    #Apply Gabor filters to stimuli\n",
    "    output_ref=np.matmul(ssn.gabor_filters, test_data['ref'])*ssn.A\n",
    "    output_target=np.matmul(ssn.gabor_filters, test_data['target'])*ssn.A\n",
    "\n",
    "    #Rectify output\n",
    "    SSN_input_ref=np.maximum(0, output_ref)\n",
    "    SSN_input_target=np.maximum(0, output_target)\n",
    "\n",
    "    #Input to SSN\n",
    "    r_init = np.zeros(SSN_input_ref.shape[0])\n",
    "\n",
    "    fp_ref, _ = ssn.fixed_point_r(SSN_input_ref, r_init=r_init, **conv_pars)\n",
    "    x_ref = ssn.apply_bounding_box(fp_ref, size=3.2)\n",
    "\n",
    "    fp_target, _ = ssn.fixed_point_r(SSN_input_target, r_init=r_init, **conv_pars)\n",
    "    x_target = ssn.apply_bounding_box(fp_target, size=3.2)\n",
    "\n",
    "    #Apply sigmoid function - combine ref and target\n",
    "    x = sigmoid( np.dot(opt_pars['w_sig'], (x_ref.ravel() - x_target.ravel())) + opt_pars['b_sig'])\n",
    "    \n",
    "    #compare prediction to label\n",
    "    pred_label = np.round(x)\n",
    "\n",
    "    #Calculate binary cross entropy loss\n",
    "    loss=binary_loss(test_data['label'], x)\n",
    "    \n",
    "    return loss, pred_label\n",
    "\n",
    "def vmap_eval(opt_pars, ssn_pars, grid_pars, conn_pars, test_data, filter_pars,  conv_pars):\n",
    "    \n",
    "    eval_vmap = vmap(eval_model, in_axes = ({'b_sig': None, 'logJ_2x2': None, 'logs_2x2': None, 'w_sig': None}, None, None, {'PERIODIC': None, 'p_local': [None, None], 'sigma_oris': None},  {'ref':0, 'target':0, 'label':0}, {'conv_factor': None, 'degree_per_pixel': None, 'edge_deg': None, 'k': None, 'sigma_g': None}, {'Tmax': None, 'dt': None, 'silent': None, 'verbose': None, 'xtol': None}) )\n",
    "    losses, pred_labels = eval_vmap(opt_pars, ssn_pars, grid_pars, conn_pars, test_data, filter_pars,  conv_pars)\n",
    "    \n",
    "    accuracy = np.sum(test_data['label'] == pred_labels)/len(test_data['label']) \n",
    "    \n",
    "    vmap_loss= np.mean(losses)\n",
    "    \n",
    "    return vmap_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5d639242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.029492578\n",
      "0.17246619\n",
      "0.155092\n",
      "0.06509497\n",
      "-0.035398982\n",
      "-0.10405494\n",
      "-0.3808349\n",
      "0.022488013\n",
      "-0.35331386\n",
      "-0.028675968\n",
      "-0.18402055\n",
      "-0.4617661\n",
      "0.052420754\n",
      "0.07784064\n",
      "-0.34543487\n",
      "-0.07090875\n",
      "0.078980304\n",
      "-0.16584781\n",
      "-0.44027418\n",
      "-0.16659573\n",
      "-0.2857178\n",
      "-0.27898508\n",
      "0.31699798\n",
      "-0.16648431\n",
      "0.17404361\n",
      "0.06896632\n",
      "0.06442323\n",
      "0.09719102\n",
      "0.091520265\n",
      "-0.15207894\n",
      "-0.14929603\n",
      "0.49952355\n",
      "0.28899094\n",
      "-0.017035412\n",
      "0.07258329\n",
      "0.03103529\n",
      "-0.0013342563\n",
      "0.045277845\n",
      "0.055535436\n",
      "-0.16484976\n",
      "-0.030420557\n",
      "0.015541026\n",
      "0.29235873\n",
      "-0.21536985\n",
      "-0.16431247\n",
      "0.10392799\n",
      "-0.035985433\n",
      "-0.18304285\n",
      "0.24859548\n",
      "0.09624269\n",
      "0.121746615\n",
      "-0.06740898\n",
      "0.5067969\n",
      "0.1442144\n",
      "-0.07963194\n",
      "-0.2553699\n",
      "0.014697698\n",
      "0.03550355\n",
      "-0.19317183\n",
      "-0.26313394\n",
      "0.022527648\n",
      "0.31488392\n",
      "-0.21827042\n",
      "-0.1459861\n",
      "0.15279333\n",
      "0.0018651752\n",
      "-0.27461946\n",
      "-0.28915852\n",
      "-0.08333664\n",
      "-0.020681921\n",
      "0.13305351\n",
      "-0.25832534\n",
      "-0.18998267\n",
      "0.4046653\n",
      "-0.06035649\n",
      "0.19500443\n",
      "-0.15255456\n",
      "-0.12465968\n",
      "-0.057451893\n",
      "0.011458481\n",
      "-0.22376874\n",
      "-0.07796078\n",
      "-0.18848473\n",
      "0.3088711\n",
      "-0.022337638\n",
      "-0.20846352\n",
      "0.0034598485\n",
      "-0.2212828\n",
      "-0.20737705\n",
      "-0.13893394\n",
      "0.08033147\n",
      "0.54055417\n",
      "0.02603727\n",
      "-0.0869055\n",
      "-0.09079089\n",
      "0.09735749\n",
      "-0.1571953\n",
      "-0.04497405\n",
      "0.0679423\n",
      "-0.16147843\n",
      "mean accuracy 0.5013999938964844\n",
      "std accuracy 0.18155451118946075\n"
     ]
    }
   ],
   "source": [
    "#Network parameters\n",
    "class ssn_pars():\n",
    "    n = 2\n",
    "    k = 0.04\n",
    "    tauE = 30 # in ms\n",
    "    tauI = 10 # in ms\n",
    "    psi = 0.774\n",
    "    tau_s = np.array([5, 7, 100]) #in ms, AMPA, GABA, NMDA current decay time constants\n",
    "    \n",
    "\n",
    "#Grid parameters\n",
    "class grid_pars():\n",
    "    gridsize_Nx = 9 # grid-points across each edge # gives rise to dx = 0.8 mm\n",
    "    gridsize_deg = 2 * 1.6 # edge length in degrees\n",
    "    magnif_factor = 2  # mm/deg\n",
    "    hyper_col = 0.8 # mm   \n",
    "    sigma_RF = 0.4 # deg (visual angle)\n",
    "\n",
    "# Caleb's params for the full (with local) model:\n",
    "Js0 = [1.82650658, 0.68194475, 2.06815311, 0.5106321]\n",
    "gE, gI = 0.57328625, 0.26144141\n",
    "\n",
    "sigEE, sigIE = 0.2, 0.40\n",
    "sigEI, sigII = .09, .09\n",
    "conn_pars = dict(\n",
    "    PERIODIC = False,\n",
    "    p_local = [.4, 0.7], # [p_local_EE, p_local_IE],\n",
    "    sigma_oris = 1000) # sigma_oris\n",
    "\n",
    "\n",
    "make_J2x2 = lambda Jee, Jei, Jie, Jii: np.array([[Jee, -Jei], [Jie,  -Jii]]) * np.pi * ssn_pars.psi\n",
    "J_2x2 = make_J2x2(*Js0)\n",
    "s_2x2 = np.array([[sigEE, sigEI],[sigIE, sigII]])\n",
    "\n",
    "#Positive reparameterization\n",
    "signs=np.array([[1, -1], [1, -1]])\n",
    "logJ_2x2 =np.log(J_2x2*signs)\n",
    "logs_2x2 = np.log(s_2x2)\n",
    "\n",
    "accuracies=[]\n",
    "\n",
    "for i in range(100):\n",
    "    #Sigmoid parameters\n",
    "    N_neurons = 25\n",
    "    #key = random.PRNGKey(7)\n",
    "    key, _ = random.split(key)\n",
    "    w_sig = random.normal(key, shape = (N_neurons,)) / np.sqrt(N_neurons)\n",
    "    b_sig = 0.0\n",
    "\n",
    "    print(w_sig[0])\n",
    "\n",
    "    #Optimization pars\n",
    "    opt_pars = dict(logJ_2x2 = logJ_2x2, logs_2x2 = logs_2x2, w_sig = w_sig, b_sig=b_sig)\n",
    "\n",
    "    #Parameters exclusive to Gabor filters\n",
    "    filter_pars = dict(sigma_g = sigma_g, conv_factor = grid_pars.magnif_factor)\n",
    "    filter_pars.update(general_pars) \n",
    "\n",
    "    #Convergence parameters\n",
    "    conv_pars=dict(dt = 1, xtol = 1e-5, Tmax = 200, verbose=False, silent=True)\n",
    "\n",
    "\n",
    "    test_iterator = iter(test_dataloader)\n",
    "    test_data = next(test_iterator)\n",
    "    test_data['ref'] = test_data['ref'].numpy()\n",
    "    test_data['target'] = test_data['target'].numpy()\n",
    "    test_data['label'] = test_data['label'].numpy()\n",
    "\n",
    "    val_loss, accuracy= vmap_eval(opt_pars, ssn_pars, grid_pars, conn_pars, test_data, filter_pars,  conv_pars)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    #print('Before training  -- loss: {}, accuracy: {} '.format(val_loss, accuracy))\n",
    "\n",
    "print('mean accuracy {}'.format(np.mean(np.array(accuracies))))\n",
    "print('std accuracy {}'.format(np.std(np.array(accuracies))))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f7155e00",
   "metadata": {},
   "source": [
    "contrast = 0.5, mean accuracy 0.5307999849319458 (mean accuracy 0.5013999938964844)\n",
    "std accuracy 0.1768936514854431 (std accuracy 0.18155451118946075)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319697d4",
   "metadata": {},
   "source": [
    "contrast = 0.8\n",
    "mean accuracy 0.5005999803543091\n",
    "std accuracy0.1579735428094864"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9f0421",
   "metadata": {},
   "source": [
    "contrast = 0.99 mean accuracy 0.4772000014781952\n",
    "std accuracy 0.14111045002937317"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "38d735a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training  -- loss: 0.5459374785423279, accuracy: 0.6600000262260437 \n",
      "Training loss: 104.8504638671875 ¦ Validation -- loss: 0.48505544662475586, accuracy: 0.6800000071525574 at epoch 1, (time 55.28361701965332)\n",
      "Training loss: 93.47003173828125 ¦ Validation -- loss: 0.41788673400878906, accuracy: 0.7599999904632568 at epoch 2, (time 55.12404465675354)\n",
      "Training loss: 81.01006317138672 ¦ Validation -- loss: 0.34719958901405334, accuracy: 0.800000011920929 at epoch 3, (time 55.708760499954224)\n",
      "Training loss: 68.13202667236328 ¦ Validation -- loss: 0.2796390950679779, accuracy: 0.8199999928474426 at epoch 4, (time 55.38471078872681)\n",
      "Training loss: 50.94453430175781 ¦ Validation -- loss: 0.1730218529701233, accuracy: 0.8999999761581421 at epoch 5, (time 55.07560420036316)\n",
      "Training loss: 19.09897232055664 ¦ Validation -- loss: 0.06391000747680664, accuracy: 1.0 at epoch 6, (time 54.87607789039612)\n",
      "Training loss: 4.007383346557617 ¦ Validation -- loss: 0.010353709571063519, accuracy: 1.0 at epoch 7, (time 55.01701021194458)\n",
      "Training loss: 1.3784871101379395 ¦ Validation -- loss: 0.003559584030881524, accuracy: 1.0 at epoch 8, (time 55.485280990600586)\n",
      "Training loss: 0.40730565786361694 ¦ Validation -- loss: 0.0014485748251900077, accuracy: 1.0 at epoch 9, (time 54.85766649246216)\n",
      "Training loss: 0.20897163450717926 ¦ Validation -- loss: 0.0011794674210250378, accuracy: 1.0 at epoch 10, (time 53.836286544799805)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [50], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#OFFSET - 0.5, eta = 10e-4\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m vmap_pars, vmap_val_loss, acc \u001b[38;5;241m=\u001b[39m train_SSN_vmap(opt_pars, ssn_pars, grid_pars, conn_pars, train_dataloader, test_dataloader, filter_pars,  conv_pars, batches \u001b[38;5;241m=\u001b[39m number_batches, epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m)\n",
      "Cell \u001b[0;32mIn [49], line 108\u001b[0m, in \u001b[0;36mtrain_SSN_vmap\u001b[0;34m(opt_pars, ssn_pars, grid_pars, conn_pars, train_dataloader, test_dataloader, filter_pars, conv_pars, batches, epochs, eta)\u001b[0m\n\u001b[1;32m    104\u001b[0m epoch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m#Evaluate model at the end of each epoch\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m val_loss, accuracy\u001b[38;5;241m=\u001b[39m \u001b[43mvmap_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt_pars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mssn_pars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid_pars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn_pars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_pars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mconv_pars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining loss: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m ¦ Validation -- loss: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, accuracy: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m at epoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, (time \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch_loss, val_loss, accuracy, epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, epoch_time))\n\u001b[1;32m    110\u001b[0m val_loss_per_epoch\u001b[38;5;241m.\u001b[39mappend(val_loss)\n",
      "Cell \u001b[0;32mIn [49], line 162\u001b[0m, in \u001b[0;36mvmap_eval\u001b[0;34m(opt_pars, ssn_pars, grid_pars, conn_pars, test_data, filter_pars, conv_pars)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvmap_eval\u001b[39m(opt_pars, ssn_pars, grid_pars, conn_pars, test_data, filter_pars,  conv_pars):\n\u001b[1;32m    161\u001b[0m     eval_vmap \u001b[38;5;241m=\u001b[39m vmap(eval_model, in_axes \u001b[38;5;241m=\u001b[39m ({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb_sig\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogJ_2x2\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogs_2x2\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw_sig\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPERIODIC\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp_local\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigma_oris\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m},  {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mref\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0\u001b[39m}, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv_factor\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdegree_per_pixel\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_deg\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigma_g\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTmax\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdt\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msilent\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxtol\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}) )\n\u001b[0;32m--> 162\u001b[0m     losses, pred_labels \u001b[38;5;241m=\u001b[39m \u001b[43meval_vmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt_pars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mssn_pars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid_pars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn_pars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_pars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mconv_pars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m pred_labels)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]) \n\u001b[1;32m    166\u001b[0m     vmap_loss\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(losses)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/code/env/lib/python3.8/site-packages/jax/_src/api.py:1648\u001b[0m, in \u001b[0;36mvmap.<locals>.vmap_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1644\u001b[0m in_axes_flat \u001b[38;5;241m=\u001b[39m flatten_axes(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvmap in_axes\u001b[39m\u001b[38;5;124m\"\u001b[39m, in_tree, (in_axes, \u001b[38;5;241m0\u001b[39m), kws\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1645\u001b[0m axis_size_ \u001b[38;5;241m=\u001b[39m (axis_size \u001b[38;5;28;01mif\u001b[39;00m axis_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[1;32m   1646\u001b[0m               _mapped_axis_size(in_tree, args_flat, in_axes_flat, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvmap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1647\u001b[0m                                 kws\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m-> 1648\u001b[0m out_flat \u001b[38;5;241m=\u001b[39m \u001b[43mbatching\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_size_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_axes_flat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1650\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mflatten_axes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvmap out_axes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_axes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1651\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspmd_axis_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspmd_axis_name\u001b[49m\n\u001b[1;32m   1652\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs_flat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1653\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree_unflatten(out_tree(), out_flat)\n",
      "File \u001b[0;32m~/code/env/lib/python3.8/site-packages/jax/linear_util.py:168\u001b[0m, in \u001b[0;36mWrappedFun.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m gen \u001b[38;5;241m=\u001b[39m gen_static_args \u001b[38;5;241m=\u001b[39m out_store \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 168\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m   \u001b[38;5;66;03m# Some transformations yield from inside context managers, so we have to\u001b[39;00m\n\u001b[1;32m    171\u001b[0m   \u001b[38;5;66;03m# interrupt them before reraising the exception. Otherwise they will only\u001b[39;00m\n\u001b[1;32m    172\u001b[0m   \u001b[38;5;66;03m# get garbage-collected at some later time, running their cleanup tasks\u001b[39;00m\n\u001b[1;32m    173\u001b[0m   \u001b[38;5;66;03m# only after this exception is handled, which can corrupt the global\u001b[39;00m\n\u001b[1;32m    174\u001b[0m   \u001b[38;5;66;03m# state.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m   \u001b[38;5;28;01mwhile\u001b[39;00m stack:\n",
      "Cell \u001b[0;32mIn [49], line 129\u001b[0m, in \u001b[0;36meval_model\u001b[0;34m(opt_pars, ssn_pars, grid_pars, conn_pars, test_data, filter_pars, conv_pars)\u001b[0m\n\u001b[1;32m    126\u001b[0m s_2x2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(opt_pars[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogs_2x2\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m#Initialise network\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m ssn\u001b[38;5;241m=\u001b[39m\u001b[43mSSN2DTopoV1_AMPAGABA_ONOFF\u001b[49m\u001b[43m(\u001b[49m\u001b[43mssn_pars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mssn_pars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid_pars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrid_pars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn_pars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconn_pars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_pars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilter_pars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mJ_2x2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mJ_2x2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms_2x2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms_2x2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m#Apply Gabor filters to stimuli\u001b[39;00m\n\u001b[1;32m    132\u001b[0m output_ref\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mmatmul(ssn\u001b[38;5;241m.\u001b[39mgabor_filters, test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mref\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m*\u001b[39mssn\u001b[38;5;241m.\u001b[39mA\n",
      "File \u001b[0;32m~/code/ssn-simulator/SSN_classes_jax.py:288\u001b[0m, in \u001b[0;36mSSN2DTopoV1_ONOFF.__init__\u001b[0;34m(self, ssn_pars, grid_pars, conn_pars, filter_pars, J_2x2, s_2x2, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconn_pars \u001b[38;5;241m=\u001b[39m conn_pars\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_maps(grid_pars)\n\u001b[0;32m--> 288\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgabor_filters, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mA \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_gabor_filters\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfilter_pars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn_pars \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;66;03m# conn_pars = None allows for ssn-object initialization without a W\u001b[39;00m\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_W(J_2x2, s_2x2, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconn_pars)\n",
      "File \u001b[0;32m~/code/ssn-simulator/SSN_classes_jax.py:595\u001b[0m, in \u001b[0;36mSSN2DTopoV1_ONOFF.create_gabor_filters\u001b[0;34m(self, edge_deg, k, sigma_g, conv_factor, degree_per_pixel)\u001b[0m\n\u001b[1;32m    590\u001b[0m i_off_filters \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m i_filters\n\u001b[1;32m    593\u001b[0m SSN_filters\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mvstack([e_filters, i_filters, e_off_filters, i_off_filters])\n\u001b[0;32m--> 595\u001b[0m A\u001b[38;5;241m=\u001b[39m \u001b[43mfind_A\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreturn_all\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconv_factor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma_g\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msigma_g\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_deg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_deg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mdegree_per_pixel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdegree_per_pixel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mori_map\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m SSN_filters, A\n",
      "File \u001b[0;32m~/code/ssn-simulator/util.py:424\u001b[0m, in \u001b[0;36mfind_A\u001b[0;34m(conv_factor, k, sigma_g, edge_deg, degree_per_pixel, indices, return_all)\u001b[0m\n\u001b[1;32m    422\u001b[0m gabor\u001b[38;5;241m=\u001b[39mGaborFilter(theta\u001b[38;5;241m=\u001b[39mori, x_i\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, y_i\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, edge_deg\u001b[38;5;241m=\u001b[39medge_deg, k\u001b[38;5;241m=\u001b[39mk, sigma_g\u001b[38;5;241m=\u001b[39msigma_g, degree_per_pixel\u001b[38;5;241m=\u001b[39mdegree_per_pixel)\n\u001b[1;32m    423\u001b[0m test_grating\u001b[38;5;241m=\u001b[39mBW_Grating(ori_deg\u001b[38;5;241m=\u001b[39mori, edge_deg\u001b[38;5;241m=\u001b[39medge_deg, k\u001b[38;5;241m=\u001b[39mk, degree_per_pixel\u001b[38;5;241m=\u001b[39mdegree_per_pixel, outer_radius\u001b[38;5;241m=\u001b[39medge_deg\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m, inner_radius\u001b[38;5;241m=\u001b[39medge_deg\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m, grating_contrast\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.99\u001b[39m)\n\u001b[0;32m--> 424\u001b[0m test_stimuli\u001b[38;5;241m=\u001b[39m\u001b[43mtest_grating\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBW_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;66;03m#multiply filter and stimuli\u001b[39;00m\n\u001b[1;32m    427\u001b[0m output_gabor\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mmatmul(gabor\u001b[38;5;241m.\u001b[39mfilter\u001b[38;5;241m.\u001b[39mravel(), test_stimuli\u001b[38;5;241m.\u001b[39mravel())\n",
      "File \u001b[0;32m~/code/ssn-simulator/util.py:335\u001b[0m, in \u001b[0;36mBW_Grating.BW_image\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mBW_image\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 335\u001b[0m     original\u001b[38;5;241m=\u001b[39mnumpy\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, dtype\u001b[38;5;241m=\u001b[39mnumpy\u001b[38;5;241m.\u001b[39mfloat16)\n\u001b[1;32m    336\u001b[0m     image\u001b[38;5;241m=\u001b[39mnumpy\u001b[38;5;241m.\u001b[39msum(original, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m) \n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrop_f:\n",
      "File \u001b[0;32m~/code/ssn-simulator/util.py:282\u001b[0m, in \u001b[0;36mJiaGrating.image\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    279\u001b[0m overrado \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mnonzero(edge_control \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minner_radius)\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx_x, idx_y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39moverrado):\n\u001b[0;32m--> 282\u001b[0m     annulus[idx_x, idx_y] \u001b[38;5;241m=\u001b[39m annulus[idx_x, idx_y] \u001b[38;5;241m*\u001b[39m numpy\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_control\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx_y\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner_radius\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpixel_per_degree\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msmooth_sd\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)    \n\u001b[1;32m    284\u001b[0m gabor_sti \u001b[38;5;241m=\u001b[39m _GRAY \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrating_contrast \u001b[38;5;241m*\u001b[39m numpy\u001b[38;5;241m.\u001b[39mcos(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39mpi \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspatial_freq \u001b[38;5;241m*\u001b[39m (y \u001b[38;5;241m*\u001b[39m numpy\u001b[38;5;241m.\u001b[39msin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mangle) \u001b[38;5;241m+\u001b[39m x \u001b[38;5;241m*\u001b[39m numpy\u001b[38;5;241m.\u001b[39mcos(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mangle)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mphase))\n\u001b[1;32m    286\u001b[0m gabor_sti[numpy\u001b[38;5;241m.\u001b[39msqrt(numpy\u001b[38;5;241m.\u001b[39mpower(x, \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m+\u001b[39m numpy\u001b[38;5;241m.\u001b[39mpower(y, \u001b[38;5;241m2\u001b[39m)) \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrating_size] \u001b[38;5;241m=\u001b[39m _GRAY\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#OFFSET - 5, eta = 10e-4\n",
    "vmap_pars, vmap_val_loss, acc = train_SSN_vmap(opt_pars, ssn_pars, grid_pars, conn_pars, train_dataloader, test_dataloader, filter_pars,  conv_pars, batches = number_batches, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2aea2748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training  -- loss: 0.7708415985107422, accuracy: 0.3400000035762787 \n",
      "Training loss: 155.9490966796875 ¦ Validation -- loss: 0.7486924529075623, accuracy: 0.3400000035762787 at epoch 1, (time 53.977357149124146)\n",
      "Training loss: 152.0327911376953 ¦ Validation -- loss: 0.7348071336746216, accuracy: 0.36000001430511475 at epoch 2, (time 53.79437446594238)\n",
      "Training loss: 149.38291931152344 ¦ Validation -- loss: 0.7255972623825073, accuracy: 0.3799999952316284 at epoch 3, (time 54.45169234275818)\n",
      "Training loss: 147.525146484375 ¦ Validation -- loss: 0.7191407680511475, accuracy: 0.4399999976158142 at epoch 4, (time 53.74654006958008)\n",
      "Training loss: 146.1613006591797 ¦ Validation -- loss: 0.7143919467926025, accuracy: 0.4399999976158142 at epoch 5, (time 54.12783145904541)\n",
      "Training loss: 145.11245727539062 ¦ Validation -- loss: 0.7107369899749756, accuracy: 0.4399999976158142 at epoch 6, (time 53.79789471626282)\n",
      "Training loss: 144.2670440673828 ¦ Validation -- loss: 0.7077839374542236, accuracy: 0.4399999976158142 at epoch 7, (time 54.3044855594635)\n",
      "Training loss: 143.55780029296875 ¦ Validation -- loss: 0.7053076028823853, accuracy: 0.4399999976158142 at epoch 8, (time 54.2173171043396)\n",
      "Training loss: 142.94349670410156 ¦ Validation -- loss: 0.7031652927398682, accuracy: 0.4399999976158142 at epoch 9, (time 53.64901518821716)\n",
      "Training loss: 142.39767456054688 ¦ Validation -- loss: 0.7012598514556885, accuracy: 0.4399999976158142 at epoch 10, (time 55.24867391586304)\n",
      "Training loss: 141.90272521972656 ¦ Validation -- loss: 0.6995232701301575, accuracy: 0.4399999976158142 at epoch 11, (time 54.38286805152893)\n",
      "Training loss: 141.44627380371094 ¦ Validation -- loss: 0.6979093551635742, accuracy: 0.46000000834465027 at epoch 12, (time 53.482595682144165)\n",
      "Training loss: 141.01922607421875 ¦ Validation -- loss: 0.6963847279548645, accuracy: 0.47999998927116394 at epoch 13, (time 53.77311182022095)\n",
      "Training loss: 140.61448669433594 ¦ Validation -- loss: 0.694923996925354, accuracy: 0.47999998927116394 at epoch 14, (time 53.493242025375366)\n",
      "Training loss: 140.22650146484375 ¦ Validation -- loss: 0.6935071349143982, accuracy: 0.47999998927116394 at epoch 15, (time 53.48341083526611)\n",
      "Training loss: 139.8507080078125 ¦ Validation -- loss: 0.6921171545982361, accuracy: 0.5199999809265137 at epoch 16, (time 53.779125928878784)\n",
      "Training loss: 139.4833526611328 ¦ Validation -- loss: 0.6907406449317932, accuracy: 0.5 at epoch 17, (time 53.870298862457275)\n",
      "Training loss: 139.12132263183594 ¦ Validation -- loss: 0.6893656849861145, accuracy: 0.5199999809265137 at epoch 18, (time 53.55506896972656)\n",
      "Training loss: 138.76187133789062 ¦ Validation -- loss: 0.6879817247390747, accuracy: 0.5199999809265137 at epoch 19, (time 53.56416201591492)\n",
      "Training loss: 138.40255737304688 ¦ Validation -- loss: 0.6865794062614441, accuracy: 0.5199999809265137 at epoch 20, (time 53.69513654708862)\n"
     ]
    }
   ],
   "source": [
    "#OFFSET - 05, eta = 10e-4\n",
    "vmap_pars_05, vmap_val_loss_05, acc_05 = train_SSN_vmap(opt_pars, ssn_pars, grid_pars, conn_pars, train_dataloader, test_dataloader, filter_pars,  conv_pars, batches = number_batches, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "61d0dc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training  -- loss: 0.6479934453964233, accuracy: 0.699999988079071 \n",
      "Training loss: 137.92486572265625 ¦ Validation -- loss: 0.6421316862106323, accuracy: 0.7400000095367432 at epoch 1, (time 54.21994471549988)\n",
      "Training loss: 136.59756469726562 ¦ Validation -- loss: 0.6350752115249634, accuracy: 0.7799999713897705 at epoch 2, (time 55.3475604057312)\n",
      "Training loss: 135.12440490722656 ¦ Validation -- loss: 0.6258025765419006, accuracy: 0.8199999928474426 at epoch 3, (time 55.09902834892273)\n",
      "Training loss: 133.29287719726562 ¦ Validation -- loss: 0.6125142574310303, accuracy: 0.8199999928474426 at epoch 4, (time 54.1776180267334)\n",
      "Training loss: 130.800537109375 ¦ Validation -- loss: 0.5912361145019531, accuracy: 0.8399999737739563 at epoch 5, (time 53.83504009246826)\n",
      "Training loss: 127.19683837890625 ¦ Validation -- loss: 0.5565797090530396, accuracy: 0.8600000143051147 at epoch 6, (time 55.08782172203064)\n",
      "Training loss: 121.86160278320312 ¦ Validation -- loss: 0.5024295449256897, accuracy: 0.8600000143051147 at epoch 7, (time 56.03807997703552)\n",
      "Training loss: 109.46571350097656 ¦ Validation -- loss: 0.41957953572273254, accuracy: 0.8199999928474426 at epoch 8, (time 53.951579570770264)\n",
      "Training loss: 76.9013442993164 ¦ Validation -- loss: 0.27264687418937683, accuracy: 0.8999999761581421 at epoch 9, (time 54.64432978630066)\n",
      "Training loss: 59.7633056640625 ¦ Validation -- loss: 0.2710249722003937, accuracy: 0.9200000166893005 at epoch 10, (time 53.860480308532715)\n",
      "Training loss: 55.6633415222168 ¦ Validation -- loss: 0.22005920112133026, accuracy: 0.9200000166893005 at epoch 11, (time 53.96526288986206)\n",
      "Training loss: 49.375850677490234 ¦ Validation -- loss: 0.21086274087429047, accuracy: 0.9399999976158142 at epoch 12, (time 53.892722845077515)\n",
      "Training loss: 46.85035705566406 ¦ Validation -- loss: 0.18622928857803345, accuracy: 0.9599999785423279 at epoch 13, (time 53.79562473297119)\n",
      "Training loss: 43.23042297363281 ¦ Validation -- loss: 0.17728681862354279, accuracy: 0.9599999785423279 at epoch 14, (time 55.69255566596985)\n",
      "Training loss: 41.291595458984375 ¦ Validation -- loss: 0.16344863176345825, accuracy: 0.9599999785423279 at epoch 15, (time 59.40362334251404)\n",
      "Training loss: 38.935516357421875 ¦ Validation -- loss: 0.15541771054267883, accuracy: 0.9599999785423279 at epoch 16, (time 55.256935119628906)\n",
      "Training loss: 37.31391906738281 ¦ Validation -- loss: 0.14672088623046875, accuracy: 0.9599999785423279 at epoch 17, (time 59.786200761795044)\n",
      "Training loss: 35.65369415283203 ¦ Validation -- loss: 0.139839768409729, accuracy: 0.9599999785423279 at epoch 18, (time 59.83045744895935)\n",
      "Training loss: 34.267967224121094 ¦ Validation -- loss: 0.13355979323387146, accuracy: 0.9599999785423279 at epoch 19, (time 56.08493423461914)\n",
      "Training loss: 32.99732971191406 ¦ Validation -- loss: 0.12787668406963348, accuracy: 0.9599999785423279 at epoch 20, (time 54.65011215209961)\n"
     ]
    }
   ],
   "source": [
    "#OFFSET - 05, eta = 10e-4\n",
    "vmap_pars_0_25, vmap_val_loss_05_2, acc_05_2 = train_SSN_vmap(opt_pars, ssn_pars, grid_pars, conn_pars, train_dataloader, test_dataloader, filter_pars,  conv_pars, batches = number_batches, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69af927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
