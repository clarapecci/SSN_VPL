{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3f6c9db",
   "metadata": {},
   "source": [
    "## TRAINING IMPLEMENTATION "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0482e672",
   "metadata": {},
   "source": [
    "In this notebook: \n",
    "- training script to be run on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b778e5e",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a96f7e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time, os, json\n",
    "import pandas as pd\n",
    "from scipy import stats \n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import jax\n",
    "from jax import random\n",
    "from jax.config import config \n",
    "import jax.numpy as np\n",
    "from jax import vmap\n",
    "import pdb\n",
    "import optax\n",
    "import time\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy\n",
    "import torch\n",
    "\n",
    "#config.update('jax_debug_nans', True)\n",
    "from SSN_classes_jax import SSN2DTopoV1_AMPAGABA_ONOFF\n",
    "from util import GaborFilter, BW_Grating, find_A, create_gabor_filters, create_gratings\n",
    "\n",
    "#initialize key\n",
    "key = random.PRNGKey(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735f18bf",
   "metadata": {},
   "source": [
    "->Check GPU available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "769bbfcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "[CpuDevice(id=0)]\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(jax.devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b71f005",
   "metadata": {},
   "source": [
    "## 2. PARAMETERS TO DEFINE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246fdcd9",
   "metadata": {},
   "source": [
    "### 2.1 Stimuli parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c78a1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gabor parameters \n",
    "sigma_g= 0.5\n",
    "k = np.pi/(6*sigma_g)\n",
    "\n",
    "#Stimuli parameters\n",
    "ref_ori = 55\n",
    "offset = 5\n",
    "\n",
    "#Assemble parameters in dictionary\n",
    "general_pars = dict(k=k , edge_deg=3.2,  degree_per_pixel=0.05)\n",
    "stimuli_pars = dict(outer_radius=3, inner_radius=2.5, grating_contrast=0.8, std = 15, jitter_val = 5, snr = 1)\n",
    "stimuli_pars.update(general_pars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def46ec0",
   "metadata": {},
   "source": [
    "### 2.2. Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2864d83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Network parameters\n",
    "class ssn_pars():\n",
    "    n = 2\n",
    "    k = 0.04\n",
    "    tauE = 30 # in ms\n",
    "    tauI = 10 # in ms~\n",
    "    psi = 0.774\n",
    "    tau_s = np.array([5, 7, 100]) #in ms, AMPA, GABA, NMDA current decay time constants\n",
    "    \n",
    "\n",
    "#Grid parameters\n",
    "class grid_pars():\n",
    "    gridsize_Nx = 9 # grid-points across each edge # gives rise to dx = 0.8 mm\n",
    "    gridsize_deg = 2 * 1.6 # edge length in degrees\n",
    "    magnif_factor = 2  # mm/deg\n",
    "    hyper_col = 0.8 # mm   \n",
    "    sigma_RF = 0.4 # deg (visual angle)\n",
    "\n",
    "# Caleb's params for the full (with local) model:\n",
    "Js0 = [1.82650658, 0.68194475, 2.06815311, 0.5106321]\n",
    "gE, gI = 0.57328625, 0.26144141\n",
    "\n",
    "sigEE, sigIE = 0.2, 0.40\n",
    "sigEI, sigII = .09, .09\n",
    "conn_pars = dict(\n",
    "    PERIODIC = False,\n",
    "    p_local = [.4, 0.7], # [p_local_EE, p_local_IE],\n",
    "    sigma_oris = 1000) # sigma_oris\n",
    "\n",
    "\n",
    "make_J2x2 = lambda Jee, Jei, Jie, Jii: np.array([[Jee, -Jei], [Jie,  -Jii]]) * np.pi * ssn_pars.psi\n",
    "J_2x2 = make_J2x2(*Js0)\n",
    "s_2x2 = np.array([[sigEE, sigEI],[sigIE, sigII]])\n",
    "\n",
    "#Positive reparameterization\n",
    "signs=np.array([[1, -1], [1, -1]])\n",
    "logJ_2x2 =np.log(J_2x2*signs)\n",
    "logs_2x2 = np.log(s_2x2)\n",
    "\n",
    "\n",
    "#Sigmoid parameters~\n",
    "N_neurons = 25\n",
    "\n",
    "key, _ = random.split(key)\n",
    "w_sig = random.normal(key, shape = (N_neurons,)) / np.sqrt(N_neurons)\n",
    "b_sig = 0.0\n",
    "\n",
    "#Excitatory and inhibitory constants for extra synaptic GABA\n",
    "c_E = 1.0\n",
    "c_I = 1.0\n",
    "\n",
    "#Optimization pars\n",
    "opt_pars = dict(logJ_2x2 = logJ_2x2, logs_2x2 = logs_2x2, w_sig = w_sig, b_sig=b_sig, c_E = c_E, c_I = c_I)\n",
    "\n",
    "\n",
    "#Parameters exclusive to Gabor filters\n",
    "filter_pars = dict(sigma_g = sigma_g, conv_factor = grid_pars.magnif_factor)\n",
    "filter_pars.update(general_pars) \n",
    "\n",
    "#Convergence parameters\n",
    "conv_pars=dict(dt = 1, xtol = 1e-5, Tmax = 200, verbose=False, silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bf068b",
   "metadata": {},
   "source": [
    "### 2.3 Training params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4693394",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name of results csv\n",
    "home_dir = os.getcwd()\n",
    "#Create directory for results\n",
    "results_dir = os.path.join(home_dir, 'results')\n",
    "if os.path.exists(results_dir) == False:\n",
    "        os.makedirs(results_dir)\n",
    "        \n",
    "        \n",
    "results_name = None #SPECIFY NAME OF RESULTS FILE\n",
    "if results_name == None:\n",
    "    results_name = 'results.csv'\n",
    "\n",
    "results_filename = os.path.join(results_dir, results_name)\n",
    "\n",
    "#Number of epochs\n",
    "epochs = 200\n",
    "num_epochs_to_save = 21\n",
    "epochs_to_save = np.linspace(1 ,epochs, num_epochs_to_save).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c92551",
   "metadata": {},
   "source": [
    "## 3. TRAINING!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffeeb43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(stimuli_pars, number=100, offset = 5, ref_ori=55):\n",
    "    \n",
    "    '''\n",
    "    Create data for given jitter and snr value for testing (not dataloader)\n",
    "    '''\n",
    "    data = create_gratings(ref_ori=ref_ori, number=number, offset=offset, **stimuli_pars)\n",
    "    train_data = next(iter(DataLoader(data, batch_size=len(data), shuffle=False)))\n",
    "    train_data['ref'] = train_data['ref'].numpy()\n",
    "    train_data['target'] = train_data['target'].numpy()\n",
    "    train_data['label'] = train_data['label'].numpy()\n",
    "    \n",
    "    return train_data\n",
    "\n",
    "\n",
    "def constant_to_vec(c_E, c_I):\n",
    "    \n",
    "    matrix_E = np.zeros((9,9))\n",
    "    matrix_E = matrix_E.at[2:7, 2:7].set(c_E)\n",
    "    vec_E = np.ravel(matrix_E)\n",
    "    \n",
    "    matrix_I = np.zeros((9,9))\n",
    "    matrix_I = matrix_I.at[2:7, 2:7].set(c_I)\n",
    "    vec_I = np.ravel(matrix_I)\n",
    "    \n",
    "    constant_vec = np.hstack((vec_E, vec_E, vec_I, vec_I))\n",
    "    return constant_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b12438d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(x))\n",
    "\n",
    "def binary_loss(n, x):\n",
    "    return - (n*np.log(x) + (1-n)*np.log(1-x))\n",
    "\n",
    "def model(opt_pars, ssn_pars, grid_pars, conn_pars, train_data, filter_pars,  conv_pars):\n",
    "    \n",
    "    signs=np.array([[1, -1], [1, -1]])\n",
    "    \n",
    "    J_2x2 =np.exp(opt_pars['logJ_2x2'])*signs\n",
    "    s_2x2 = np.exp(opt_pars['logs_2x2'])\n",
    "    \n",
    "    #Initialise network\n",
    "    ssn=SSN2DTopoV1_AMPAGABA_ONOFF(ssn_pars=ssn_pars, grid_pars=grid_pars, conn_pars=conn_pars, filter_pars=filter_pars, J_2x2=J_2x2, s_2x2=s_2x2)\n",
    "    \n",
    "    #Create vector using extrasynaptic constants\n",
    "    constant_vector = constant_to_vec(opt_pars['c_E'], opt_pars['c_I'])\n",
    "    \n",
    "    #Apply Gabor filters to stimuli\n",
    "    output_ref=np.matmul(ssn.gabor_filters, train_data['ref'])*ssn.A + constant_vector\n",
    "    output_target=np.matmul(ssn.gabor_filters, train_data['target'])*ssn.A + constant_vector\n",
    "    \n",
    "\n",
    "    #Rectify output\n",
    "    SSN_input_ref=np.maximum(0, output_ref)\n",
    "    SSN_input_target=np.maximum(0, output_target)\n",
    "\n",
    "    #Input to SSN\n",
    "    r_init = np.zeros(SSN_input_ref.shape[0])\n",
    "\n",
    "    fp_ref, _ = ssn.fixed_point_r(SSN_input_ref, r_init=r_init, **conv_pars)\n",
    "    x_ref = ssn.apply_bounding_box(fp_ref, size=3.2)\n",
    "\n",
    "    fp_target, _ = ssn.fixed_point_r(SSN_input_target, r_init=r_init, **conv_pars)\n",
    "    x_target = ssn.apply_bounding_box(fp_target, size=3.2)\n",
    "\n",
    "    #Apply sigmoid function - combine ref and target\n",
    "    x = sigmoid( np.dot(opt_pars['w_sig'], (x_ref.ravel() - x_target.ravel())) + opt_pars['b_sig'])\n",
    "\n",
    "    #Calculate binary cross entropy loss\n",
    "    loss=binary_loss(train_data['label'], x)\n",
    "   \n",
    "    return loss\n",
    "\n",
    "\n",
    "def loss(opt_pars, ssn_pars, grid_pars, conn_pars, train_data, filter_pars,  conv_pars):\n",
    "    '''\n",
    "    Calculate parallelized loss for batch of data through vmap.\n",
    "    Output:\n",
    "        mean loss of all the input images\n",
    "    '''\n",
    "    \n",
    "    vmap_model = vmap(model, in_axes = ({'b_sig': None, 'c_E':None, 'c_I': None, 'logJ_2x2': None, 'logs_2x2': None, 'w_sig': None}, None, None, {'PERIODIC': None, 'p_local': [None, None], 'sigma_oris': None},  {'ref':0, 'target':0, 'label':0}, {'conv_factor': None, 'degree_per_pixel': None, 'edge_deg': None, 'k': None, 'sigma_g': None}, {'Tmax': None, 'dt': None, 'silent': None, 'verbose': None, 'xtol': None}) )                   \n",
    "    loss = np.sum(vmap_model(opt_pars, ssn_pars, grid_pars, conn_pars, train_data, filter_pars,  conv_pars))\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def eval_model(opt_pars, ssn_pars, grid_pars, conn_pars, test_data, filter_pars,  conv_pars):\n",
    "    signs=np.array([[1, -1], [1, -1]])\n",
    "    \n",
    "    J_2x2 =np.exp(opt_pars['logJ_2x2'])*signs\n",
    "    s_2x2 = np.exp(opt_pars['logs_2x2'])\n",
    "    \n",
    "    #Initialise network\n",
    "    ssn=SSN2DTopoV1_AMPAGABA_ONOFF(ssn_pars=ssn_pars, grid_pars=grid_pars, conn_pars=conn_pars, filter_pars=filter_pars, J_2x2=J_2x2, s_2x2=s_2x2)\n",
    "\n",
    "    #Apply Gabor filters to stimuli\n",
    "    output_ref=np.matmul(ssn.gabor_filters, test_data['ref'])*ssn.A\n",
    "    output_target=np.matmul(ssn.gabor_filters, test_data['target'])*ssn.A\n",
    "\n",
    "    #Rectify output\n",
    "    SSN_input_ref=np.maximum(0, output_ref)\n",
    "    SSN_input_target=np.maximum(0, output_target)\n",
    "\n",
    "    #Input to SSN\n",
    "    r_init = np.zeros(SSN_input_ref.shape[0])\n",
    "\n",
    "    fp_ref, _ = ssn.fixed_point_r(SSN_input_ref, r_init=r_init, **conv_pars)\n",
    "    x_ref = ssn.apply_bounding_box(fp_ref, size=3.2)\n",
    "\n",
    "    fp_target, _ = ssn.fixed_point_r(SSN_input_target, r_init=r_init, **conv_pars)\n",
    "    x_target = ssn.apply_bounding_box(fp_target, size=3.2)\n",
    "    \n",
    "    dot= np.dot(opt_pars['w_sig'], (x_ref.ravel() - x_target.ravel()))\n",
    "\n",
    "    #Apply sigmoid function - combine ref and target\n",
    "    x = sigmoid( np.dot(opt_pars['w_sig'], (x_ref.ravel() - x_target.ravel())) + opt_pars['b_sig'])\n",
    "    \n",
    "    #compare prediction to label\n",
    "    pred_label = np.round(x)\n",
    "\n",
    "    #Calculate binary cross entropy loss\n",
    "    loss=binary_loss(test_data['label'], x)\n",
    "    \n",
    "    return loss, pred_label, x\n",
    "\n",
    "\n",
    "def vmap_eval(opt_pars, ssn_pars, grid_pars, conn_pars, test_data, filter_pars,  conv_pars):\n",
    "    \n",
    "    eval_vmap = vmap(eval_model, in_axes = ({'b_sig': None,  'c_E':None, 'c_I': None,  'logJ_2x2': None, 'logs_2x2': None, 'w_sig': None}, None, None, {'PERIODIC': None, 'p_local': [None, None], 'sigma_oris': None},  {'ref':0, 'target':0, 'label':0}, {'conv_factor': None, 'degree_per_pixel': None, 'edge_deg': None, 'k': None, 'sigma_g': None}, {'Tmax': None, 'dt': None, 'silent': None, 'verbose': None, 'xtol': None}) )\n",
    "    losses, pred_labels, dots = eval_vmap(opt_pars, ssn_pars, grid_pars, conn_pars, test_data, filter_pars,  conv_pars)\n",
    "    \n",
    "    accuracy = np.sum(test_data['label'] == pred_labels)/len(test_data['label']) \n",
    "    \n",
    "    vmap_loss= np.mean(losses)\n",
    "    \n",
    "    return vmap_loss, accuracy, dots\n",
    "\n",
    "\n",
    "def train_SSN_vmap(opt_pars, ssn_pars, grid_pars, conn_pars, stimuli_pars, filter_pars, conv_pars, results_filename, epochs_to_save, batch_size=20, ref_ori = 55, offset = 5, epochs=1, eta=10e-4):\n",
    "    \n",
    "    #Initialize loss\n",
    "    val_loss_per_epoch = []\n",
    "    training_losses=[]\n",
    "    accuracies=[]\n",
    "        \n",
    "    #Initialise optimizer\n",
    "    optimizer = optax.adam(eta)\n",
    "    opt_state = optimizer.init(opt_pars)\n",
    "    print('Training model for {} epochs at reference orientation {} and offset {} (batch size = {} )'.format(epochs, ref_ori, offset, batch_size))\n",
    "    \n",
    "    #Define test data - no need to iterate\n",
    "    test_data = create_data(stimuli_pars, number = batch_size, offset = offset, ref_ori = ref_ori)\n",
    "    val_loss, accuracy, _= vmap_eval(opt_pars, ssn_pars, grid_pars, conn_pars, test_data, filter_pars,  conv_pars)\n",
    "    print('Before training  -- loss: {}, accuracy: {} '.format(val_loss, accuracy))\n",
    "    val_loss_per_epoch.append(val_loss)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "    results_handle = open(results_filename, 'w')\n",
    "    results_writer=None\n",
    "\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        start_time = time.time()\n",
    "        epoch_loss = 0 \n",
    "           \n",
    "        #load next batch of data and convert\n",
    "        train_data = create_data(stimuli_pars, number = batch_size, offset = offset, ref_ori = ref_ori)\n",
    "\n",
    "        #Compute loss and gradient\n",
    "        epoch_loss, grad =jax.value_and_grad(loss)(opt_pars, ssn_pars, grid_pars, conn_pars, train_data, filter_pars,  conv_pars)\n",
    "\n",
    "        #Apply SGD through Adam optimizer per batch\n",
    "        updates, opt_state = optimizer.update(grad, opt_state)\n",
    "        opt_pars = optax.apply_updates(opt_pars, updates)\n",
    "        training_losses.append(epoch_loss)\n",
    "        \n",
    "        epoch_time = time.time() - start_time\n",
    "\n",
    "        #Save the parameters given a number of epochs\n",
    "        if epoch in epochs_to_save:\n",
    "            \n",
    "            #Evaluate model \n",
    "            test_data = create_data(stimuli_pars, number = batch_size, offset = offset, ref_ori = ref_ori)\n",
    "            val_loss, accuracy, _= vmap_eval(opt_pars, ssn_pars, grid_pars, conn_pars, test_data, filter_pars,  conv_pars)\n",
    "            print('Training loss: {} ¦ Validation -- loss: {}, accuracy: {} at epoch {}, (time {})'.format(epoch_loss, val_loss, accuracy, epoch, epoch_time))\n",
    "            val_loss_per_epoch.append(val_loss)\n",
    "            accuracies.append(accuracy)\n",
    "            \n",
    "            #Create dictionary to save desired params\n",
    "            save_params= dict(val_accuracy= accuracy, \n",
    "                J_EE= opt_pars['logJ_2x2'][0,0], J_EI = opt_pars['logJ_2x2'][0,1], \n",
    "                              J_IE = opt_pars['logJ_2x2'][0,0], J_II = opt_pars['logJ_2x2'][0,0], \n",
    "                s_EE= opt_pars['logs_2x2'][0,0], s_EI = opt_pars['logs_2x2'][0,1], \n",
    "                              s_IE = opt_pars['logJ_2x2'][0,0], s_II = opt_pars['logJ_2x2'][0,0],\n",
    "                c_E = opt_pars['c_E'], c_I = opt_pars['c_I'], \n",
    "                 epoch = epoch)\n",
    "            \n",
    "            #Only write header once\n",
    "            if results_writer is None:\n",
    "                results_writer = csv.DictWriter(results_handle, fieldnames=save_params.keys())\n",
    "                results_writer.writeheader()\n",
    "            \n",
    "            #Write results in csv file\n",
    "            results_writer.writerow(save_params)\n",
    "         \n",
    "    \n",
    "    #Reparametize parameters\n",
    "    signs=np.array([[1, -1], [1, -1]])    \n",
    "    opt_pars['logJ_2x2'] = np.exp(opt_pars['logJ_2x2'])*signs\n",
    "    opt_pars['logs_2x2'] = np.exp(opt_pars['logs_2x2'])\n",
    "    \n",
    "   \n",
    "    return opt_pars, val_loss_per_epoch, training_losses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9826b188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for 200 epochs at reference orientation 55 and offset 2 (batch size = 50 )\n",
      "Before training  -- loss: 1.005676507949829, accuracy: 0.05999999865889549 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Train model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m final_pars, val_loss, training_loss \u001b[38;5;241m=\u001b[39m train_SSN_vmap(opt_pars, ssn_pars, grid_pars, conn_pars, stimuli_pars, filter_pars,  conv_pars, results_filename, epochs_to_save \u001b[38;5;241m=\u001b[39m epochs_to_save, ref_ori \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m55\u001b[39m, offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m, epochs \u001b[38;5;241m=\u001b[39m epochs)\n",
      "Cell \u001b[0;32mIn [16], line 143\u001b[0m, in \u001b[0;36mtrain_SSN_vmap\u001b[0;34m(opt_pars, ssn_pars, grid_pars, conn_pars, stimuli_pars, filter_pars, conv_pars, results_filename, epochs_to_save, batch_size, ref_ori, offset, epochs, eta)\u001b[0m\n\u001b[1;32m    140\u001b[0m train_data \u001b[38;5;241m=\u001b[39m create_data(stimuli_pars, number \u001b[38;5;241m=\u001b[39m batch_size, offset \u001b[38;5;241m=\u001b[39m offset, ref_ori \u001b[38;5;241m=\u001b[39m ref_ori)\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m#Compute loss and gradient\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m epoch_loss, grad \u001b[38;5;241m=\u001b[39m\u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt_pars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mssn_pars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid_pars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn_pars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_pars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mconv_pars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m#Apply SGD through Adam optimizer per batch\u001b[39;00m\n\u001b[1;32m    146\u001b[0m updates, opt_state \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mupdate(grad, opt_state)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/code/env/lib/python3.8/site-packages/jax/_src/api.py:1150\u001b[0m, in \u001b[0;36mvalue_and_grad.<locals>.value_and_grad_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1148\u001b[0m _check_scalar(ans)\n\u001b[1;32m   1149\u001b[0m tree_map(partial(_check_output_dtype_grad, holomorphic), ans)\n\u001b[0;32m-> 1150\u001b[0m g \u001b[38;5;241m=\u001b[39m \u001b[43mvjp_py\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlax_internal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mans\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1151\u001b[0m g \u001b[38;5;241m=\u001b[39m g[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(argnums, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m g\n\u001b[1;32m   1152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_aux:\n",
      "File \u001b[0;32m~/code/env/lib/python3.8/site-packages/jax/_src/tree_util.py:292\u001b[0m, in \u001b[0;36m_HashableCallableShim.__call__\u001b[0;34m(self, *args, **kw)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m--> 292\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/env/lib/python3.8/site-packages/jax/_src/api.py:2505\u001b[0m, in \u001b[0;36m_vjp_pullback_wrapper\u001b[0;34m(cotangent_dtypes, cotangent_shapes, io_tree, fun, py_args)\u001b[0m\n\u001b[1;32m   2500\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mshape(arg) \u001b[38;5;241m!=\u001b[39m ct_shape:\n\u001b[1;32m   2501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2502\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of cotangent input to vjp pullback function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mshape(arg)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmust be the same as the shape of corresponding primal input \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2504\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mct_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2505\u001b[0m ans \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2506\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree_unflatten(out_tree, ans)\n",
      "File \u001b[0;32m~/code/env/lib/python3.8/site-packages/jax/_src/tree_util.py:292\u001b[0m, in \u001b[0;36m_HashableCallableShim.__call__\u001b[0;34m(self, *args, **kw)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m--> 292\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/env/lib/python3.8/site-packages/jax/interpreters/ad.py:140\u001b[0m, in \u001b[0;36mvjp.<locals>.unbound_vjp\u001b[0;34m(pvals, jaxpr, consts, *cts)\u001b[0m\n\u001b[1;32m    138\u001b[0m cts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(ct \u001b[38;5;28;01mfor\u001b[39;00m ct, pval \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(cts, pvals) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pval\u001b[38;5;241m.\u001b[39mis_known())\n\u001b[1;32m    139\u001b[0m dummy_args \u001b[38;5;241m=\u001b[39m [UndefinedPrimal(v\u001b[38;5;241m.\u001b[39maval) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m jaxpr\u001b[38;5;241m.\u001b[39minvars]\n\u001b[0;32m--> 140\u001b[0m arg_cts \u001b[38;5;241m=\u001b[39m \u001b[43mbackward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(instantiate_zeros, arg_cts)\n",
      "File \u001b[0;32m~/code/env/lib/python3.8/site-packages/jax/interpreters/ad.py:240\u001b[0m, in \u001b[0;36mbackward_pass\u001b[0;34m(jaxpr, reduce_axes, transform_stack, consts, primals_in, cotangents_in)\u001b[0m\n\u001b[1;32m    238\u001b[0m   params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(eqn\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    239\u001b[0m   call_jaxpr \u001b[38;5;241m=\u001b[39m params\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall_jaxpr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 240\u001b[0m   cts_out \u001b[38;5;241m=\u001b[39m \u001b[43mget_primitive_transpose\u001b[49m\u001b[43m(\u001b[49m\u001b[43meqn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprimitive\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m      \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall_jaxpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcts_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcts_in_avals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_axes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m eqn\u001b[38;5;241m.\u001b[39mprimitive \u001b[38;5;129;01min\u001b[39;00m reducing_transposes:\n\u001b[1;32m    243\u001b[0m   cts_out \u001b[38;5;241m=\u001b[39m reducing_transposes[eqn\u001b[38;5;241m.\u001b[39mprimitive](\n\u001b[1;32m    244\u001b[0m       reduce_axes, cts_in, \u001b[38;5;241m*\u001b[39minvals, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39meqn\u001b[38;5;241m.\u001b[39mparams)\n",
      "File \u001b[0;32m~/code/env/lib/python3.8/site-packages/jax/interpreters/ad.py:625\u001b[0m, in \u001b[0;36mcall_transpose\u001b[0;34m(primitive, params, call_jaxpr, args, ct, _, reduce_axes)\u001b[0m\n\u001b[1;32m    622\u001b[0m   in_type \u001b[38;5;241m=\u001b[39m [(v\u001b[38;5;241m.\u001b[39maval\u001b[38;5;241m.\u001b[39mupdate(shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(dbidx_map\u001b[38;5;241m.\u001b[39mget(d, d) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m v\u001b[38;5;241m.\u001b[39maval\u001b[38;5;241m.\u001b[39mshape))\n\u001b[1;32m    623\u001b[0m               \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(v\u001b[38;5;241m.\u001b[39maval) \u001b[38;5;129;01mis\u001b[39;00m core\u001b[38;5;241m.\u001b[39mDShapedArray \u001b[38;5;28;01melse\u001b[39;00m v\u001b[38;5;241m.\u001b[39maval, \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m new_invars]\n\u001b[1;32m    624\u001b[0m   fun \u001b[38;5;241m=\u001b[39m lu\u001b[38;5;241m.\u001b[39mannotate(fun, \u001b[38;5;28mtuple\u001b[39m(in_type))\n\u001b[0;32m--> 625\u001b[0m out_flat \u001b[38;5;241m=\u001b[39m \u001b[43mprimitive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree_unflatten(out_tree(), out_flat)\n",
      "File \u001b[0;32m~/code/env/lib/python3.8/site-packages/jax/core.py:1959\u001b[0m, in \u001b[0;36mCallPrimitive.bind\u001b[0;34m(self, fun, *args, **params)\u001b[0m\n\u001b[1;32m   1958\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, fun, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[0;32m-> 1959\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/env/lib/python3.8/site-packages/jax/core.py:1975\u001b[0m, in \u001b[0;36mcall_bind\u001b[0;34m(primitive, fun, *args, **params)\u001b[0m\n\u001b[1;32m   1973\u001b[0m tracers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(top_trace\u001b[38;5;241m.\u001b[39mfull_raise, args)\n\u001b[1;32m   1974\u001b[0m fun_ \u001b[38;5;241m=\u001b[39m lu\u001b[38;5;241m.\u001b[39mannotate(fun_, fun\u001b[38;5;241m.\u001b[39min_type)\n\u001b[0;32m-> 1975\u001b[0m outs \u001b[38;5;241m=\u001b[39m \u001b[43mtop_trace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprimitive\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1976\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(full_lower, apply_todos(env_trace_todo(), outs))\n",
      "File \u001b[0;32m~/code/env/lib/python3.8/site-packages/jax/core.py:701\u001b[0m, in \u001b[0;36mEvalTrace.process_call\u001b[0;34m(self, primitive, f, tracers, params)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, primitive, f, tracers, params):\n\u001b[0;32m--> 701\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprimitive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtracers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/env/lib/python3.8/site-packages/jax/_src/dispatch.py:237\u001b[0m, in \u001b[0;36m_xla_call_impl\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    234\u001b[0m compiled_fun \u001b[38;5;241m=\u001b[39m xla_callable(fun, device, backend, name, donated_invars,\n\u001b[1;32m    235\u001b[0m                             keep_unused, \u001b[38;5;241m*\u001b[39marg_specs)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompiled_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFloatingPointError\u001b[39;00m:\n\u001b[1;32m    239\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_debug_nans \u001b[38;5;129;01mor\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_debug_infs  \u001b[38;5;66;03m# compiled_fun can only raise in this case\u001b[39;00m\n",
      "File \u001b[0;32m~/code/env/lib/python3.8/site-packages/jax/_src/dispatch.py:883\u001b[0m, in \u001b[0;36m_execute_compiled\u001b[0;34m(name, compiled, input_handler, output_buffer_counts, result_handler, has_unordered_effects, ordered_effects, kept_var_idx, has_host_callbacks, *args)\u001b[0m\n\u001b[1;32m    881\u001b[0m     runtime_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    882\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 883\u001b[0m   out_flat \u001b[38;5;241m=\u001b[39m \u001b[43mcompiled\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_flat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    884\u001b[0m check_special(name, out_flat)\n\u001b[1;32m    885\u001b[0m out_bufs \u001b[38;5;241m=\u001b[39m unflatten(out_flat, output_buffer_counts)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Train model\n",
    "final_pars, val_loss, training_loss = train_SSN_vmap(opt_pars, ssn_pars, grid_pars, conn_pars, stimuli_pars, filter_pars,  conv_pars, results_filename, epochs_to_save = epochs_to_save, ref_ori = 55, offset = 2, batch_size = 50, epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f829075c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
