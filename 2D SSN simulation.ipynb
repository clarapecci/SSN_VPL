{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26134402",
   "metadata": {},
   "source": [
    "## 2D SSN simulation ~  JAX IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e06adf",
   "metadata": {},
   "source": [
    "CHANGES:\n",
    "- jax.random vs numpy.random\n",
    "- introduction of key variables to operate in random\n",
    "- np.chararray substituted -> created separate boolean array after locating indices in a list because jax doesnt support character arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4bb989c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "import jax.numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import circulant, toeplitz\n",
    "import time, os, json\n",
    "import pandas as pd\n",
    "from scipy import stats \n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from jax import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ec0fba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import SSN_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7db1ab",
   "metadata": {},
   "source": [
    "## SSN classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb286a3",
   "metadata": {},
   "source": [
    "SSN BASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "437f6805",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class _SSN_Base(object):\n",
    "    def __init__(self, n, k, Ne, Ni, tau_vec=None, W=None):\n",
    "        self.n = n\n",
    "        self.k = k\n",
    "        self.Ne = Ne\n",
    "        self.Ni = Ni\n",
    "        self.N = self.Ne + self.Ni\n",
    "        #original code - not jax compatible\n",
    "        #self.EI = np.chararray((self.N,), itemsize=1)\n",
    "        #self.EI[:Ne] = b\"E\"\n",
    "        #self.EI[Ne:] = b\"I\"\n",
    "        \n",
    "        ## JAX CHANGES ##\n",
    "        self.EI=[b\"E\"]*(self.Ne) + [b\"I\"]*(self.N - self.Ne)\n",
    "        self.condition= np.array([bool(self.EI[x]==b\"E\") for x in range(len(self.EI))])\n",
    "        \n",
    "        if tau_vec is not None:\n",
    "            self.tau_vec = tau_vec # rate time-consants of neurons. shape: (N,)\n",
    "        # elif  not hasattr(self, \"tau_vec\"):\n",
    "        #     self.tau_vec = np.random.rand(N) * 20 # in ms\n",
    "        if W is not None:\n",
    "            self.W = W # connectivity matrix. shape: (N, N)\n",
    "        # elif  not hasattr(self, \"W\"):\n",
    "        #     W = np.random.rand(N,N) / np.sqrt(self.N)\n",
    "        #     sign_vec = np.hstack(np.ones(self.Ne), -np.ones(self.Ni))\n",
    "        #     self.W = W * sign_vec[None, :] # to respect Dale\n",
    "\n",
    "    @property\n",
    "    def neuron_params(self):\n",
    "        return dict(n=self.n, k=self.k)\n",
    "\n",
    "    @property\n",
    "    def dim(self):\n",
    "        return self.N\n",
    "\n",
    "    @property\n",
    "    def tau_x_vec(self):\n",
    "        \"\"\" time constants for the generalized state-vector, x \"\"\"\n",
    "        return self.tau_vec\n",
    "\n",
    "\n",
    "    def powlaw(self, u):\n",
    "        return  self.k * np.maximum(0,u)**self.n\n",
    "\n",
    "    def drdt(self, r, inp_vec):\n",
    "        return ( -r + self.powlaw(self.W @ r + inp_vec) ) / self.tau_vec\n",
    "\n",
    "    def drdt_multi(self, r, inp_vec):\n",
    "        \"\"\"\n",
    "        Compared to self.drdt allows for inp_vec and r to be\n",
    "        matrices with arbitrary shape[1]\n",
    "        \"\"\"\n",
    "        return (( -r + self.powlaw(self.W @ r + inp_vec) ).T / self.tau_vec ).T\n",
    "\n",
    "    def dxdt(self, x, inp_vec):\n",
    "        \"\"\"\n",
    "        allowing for descendent SSN types whose state-vector, x, is different\n",
    "        than the rate-vector, r.\n",
    "        \"\"\"\n",
    "        return self.drdt(x, inp_vec)\n",
    "\n",
    "    def gains_from_v(self, v):\n",
    "        return self.n * self.k * np.maximum(0,v)**(self.n-1)\n",
    "\n",
    "    def gains_from_r(self, r):\n",
    "        return self.n * self.k**(1/self.n) * r**(1-1/self.n)\n",
    "\n",
    "    def DCjacobian(self, r):\n",
    "        \"\"\"\n",
    "        DC Jacobian (i.e. zero-frequency linear response) for\n",
    "        linearization around rate vector r\n",
    "        \"\"\"\n",
    "        Phi = self.gains_from_r(r)\n",
    "        return -np.eye(self.N) + Phi[:, None] * self.W\n",
    "\n",
    "    def jacobian(self, DCjacob=None, r=None):\n",
    "        \"\"\"\n",
    "        dynamic Jacobian for linearization around rate vector r\n",
    "        \"\"\"\n",
    "        if DCjacob is None:\n",
    "            assert r is not None\n",
    "            DCjacob = self.DCjacobian(r)\n",
    "        return DCjacob / self.tau_x_vec[:, None] # equivalent to np.diag(tau_x_vec) * DCjacob\n",
    "\n",
    "    def jacobian_eigvals(self, DCjacob=None, r=None):\n",
    "        Jacob = self.jacobian(DCjacob=DCjacob, r=r)\n",
    "        return np.linalg.eigvals(Jacob)\n",
    "\n",
    "    def inv_G(self, omega, DCjacob, r=None):\n",
    "        \"\"\"\n",
    "        inverse Green's function at angular frequency omega,\n",
    "        for linearization around rate vector r\n",
    "        \"\"\"\n",
    "        if DCjacob is None:\n",
    "            assert r is not None\n",
    "            DCjacob = self.DCjacobian(r)\n",
    "        return -1j*omega * np.diag(self.tau_x_vec) - DCjacob\n",
    "\n",
    "    def fixed_point_r(self, inp_vec, r_init=None, Tmax=500, dt=1, xtol=1e-5, PLOT=False, verbose=True):\n",
    "        if r_init is None:\n",
    "            r_init = np.zeros(inp_vec.shape) # np.zeros((self.N,))\n",
    "        drdt = lambda r : self.drdt(r, inp_vec)\n",
    "        if inp_vec.ndim > 1:\n",
    "            drdt = lambda r : self.drdt_multi(r, inp_vec)\n",
    "        r_fp, CONVG = Euler2fixedpt(drdt, r_init, Tmax, dt, xtol=xtol, PLOT=PLOT, verbose=verbose)\n",
    "        if not CONVG:\n",
    "            print('Did not reach fixed point.')\n",
    "        #else:\n",
    "        #    return r_fp\n",
    "        return r_fp, CONVG\n",
    "\n",
    "    def fixed_point(self, inp_vec, x_init=None, Tmax=500, dt=1, xtol=1e-5, PLOT=False):\n",
    "        if x_init is None:\n",
    "            x_init = np.zeros((self.dim,))\n",
    "        dxdt = lambda x : self.dxdt(x, inp_vec)\n",
    "        x_fp, CONVG = Euler2fixedpt(dxdt, x_init, Tmax, dt, xtol=xtol, PLOT=PLOT)\n",
    "        if not CONVG:\n",
    "            print('Did not reach fixed point.')\n",
    "        #else:\n",
    "        #    return x_fp\n",
    "        return x_fp, CONVG\n",
    "\n",
    "    def make_noise_cov(self, noise_pars):\n",
    "        # the script assumes independent noise to E and I, and spatially uniform magnitude of noise\n",
    "        noise_sigsq = np.hstack( (noise_pars.stdevE**2 * np.ones(self.Ne),\n",
    "                                  noise_pars.stdevI**2 * np.ones(self.Ni)) )\n",
    "        spatl_filt = np.array(1)\n",
    "\n",
    "        return noise_sigsq, spatl_filt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f44bbc",
   "metadata": {},
   "source": [
    "SSN_AMPAGABA_BASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d74022a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _SSN_AMPAGABA_Base(_SSN_Base):\n",
    "    \"\"\"\n",
    "    SSN with different synaptic receptor types.\n",
    "    Dynamics of the model assumes the instantaneous neural I/O approximation\n",
    "    suggested by Fourcaud and Brunel (2002).\n",
    "    Convention for indexing of state-vector v (which is 2N or 3N dim)\n",
    "    is according to kron(receptor_type_index, neural_index).\n",
    "    \"\"\"\n",
    "    def __init__(self,*, tau_s=[4,5,100], NMDAratio=0.4, **kwargs):\n",
    "        \"\"\"\n",
    "        tau_s = [tau_AMPA, tau_GABA, tau_NMDA] or [tau_AMPA, tau_GABA]\n",
    "          decay time-consants for synaptic currents of different receptor types.\n",
    "        NMDAratio: scalar\n",
    "          ratio of E synaptic weights that are NMDA-type\n",
    "          (model assumes this fraction is constant in all weights)\n",
    "        Good values:\n",
    "         tau_AMPA = 4, tau_GABA= 5  #in ms\n",
    "         NMDAratio = 0.3-0.4\n",
    "         tau_s can have length == 3, and yet if self.NMDAratio is 0,\n",
    "         then num_rcpt will be 2, and dynamical system will be 2 * self.N dimensional.\n",
    "         I.e. NMDA components will not be simulated even though a NMDA time-constant is defined.\n",
    "        \"\"\"\n",
    "        tau_s = np.squeeze(np.asarray(tau_s))\n",
    "        assert tau_s.size <= 3 and tau_s.ndim == 1\n",
    "        self._tau_s = tau_s\n",
    "        if tau_s.size == 3 and NMDAratio > 0:\n",
    "            self._NMDAratio = NMDAratio\n",
    "        else:\n",
    "            self._NMDAratio = 0\n",
    "\n",
    "        super(_SSN_AMPAGABA_Base, self).__init__(**kwargs)\n",
    "\n",
    "    @property\n",
    "    def dim(self):\n",
    "        return self.num_rcpt * self.N\n",
    "\n",
    "    @property\n",
    "    def num_rcpt(self):\n",
    "        if not hasattr(self, '_num_rcpt'):\n",
    "            self._num_rcpt = self._tau_s.size\n",
    "            if self._num_rcpt == 3 and self.NMDAratio == 0:\n",
    "                self._num_rcpt = 2\n",
    "        return self._num_rcpt\n",
    "\n",
    "    @property\n",
    "    def NMDAratio(self):\n",
    "        return self._NMDAratio\n",
    "\n",
    "    @NMDAratio.setter\n",
    "    def NMDAratio(self, value):\n",
    "        # if value > 0, make sure an NMDA time-constant is defined\n",
    "        if value > 0 and self._tau_s.size < 3:\n",
    "            raise ValueError(\"No NMDA time-constant defined! Change tau_s first to add NMDA constant.\")\n",
    "        # if NMDAratio is going from 0 to nonzero or vice versa, then delete _num_rcpt and _Wrcpt (so they are made de novo when needed)\n",
    "        if (value == 0 and self._NMDAratio > 0) or (value > 0 and self._NMDAratio == 0):\n",
    "            del self._Wrcpt\n",
    "            del self._num_rcpt\n",
    "        self._NMDAratio = value\n",
    "\n",
    "    @property\n",
    "    def Wrcpt(self):\n",
    "        if not hasattr(self, '_Wrcpt'): # cache it in _Wrcpt once it's been created\n",
    "            W_AMPA = (1-self.NMDAratio)* np.hstack((self.W[:,:self.Ne], np.zeros((self.N,self.Ni)) ))\n",
    "            W_GABA = np.hstack((np.zeros((self.N,self.Ne)), self.W[:,self.Ne:]))\n",
    "            Wrcpt = [W_AMPA, W_GABA]\n",
    "            if self.NMDAratio > 0:\n",
    "                W_NMDA = self.NMDAratio/(1-self.NMDAratio) * W_AMPA\n",
    "                Wrcpt.append(W_NMDA)\n",
    "            self._Wrcpt = np.vstack(Wrcpt) # shape = (self.num_rcpt*self.N, self.N)\n",
    "        return self._Wrcpt\n",
    "\n",
    "    @property\n",
    "    def tau_s(self):\n",
    "        return self._tau_s  #[:self.num_rcpt]\n",
    "\n",
    "    @tau_s.setter\n",
    "    def tau_s(self, values):\n",
    "        self._tau_s = values\n",
    "        del self._tau_s_vec   ##QUESTION 1! DELETING?\n",
    "\n",
    "    @property\n",
    "    def tau_s_vec(self):\n",
    "        if not hasattr(self, '_tau_s_vec'): # cache it once it's been created\n",
    "            self._tau_s_vec = np.kron(self._tau_s[:self.num_rcpt], np.ones(self.N))\n",
    "        return self._tau_s_vec\n",
    "\n",
    "    @property\n",
    "    def tau_x_vec(self):\n",
    "        \"\"\" time constants for the generalized state-vector, x \"\"\" ##QUESTION 2! difference between x and s vec\n",
    "        return self.tau_s_vec\n",
    "\n",
    "    @property\n",
    "    def tau_AMPA(self):\n",
    "        return self._tau_s[0]\n",
    "\n",
    "    @property\n",
    "    def tau_GABA(self):\n",
    "        return self._tau_s[1]\n",
    "\n",
    "    @property\n",
    "    def tau_NMDA(self):\n",
    "        if len(self._tau_s) == 3:\n",
    "            return self._tau_s[2]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def dvdt(self, v, inp_vec):\n",
    "        \"\"\"\n",
    "        Returns the AMPA/GABA/NMDA based dynamics, with the instantaneous\n",
    "        neural I/O approximation suggested by Fourcaud and Brunel (2002).\n",
    "        v and inp_vec are now of shape (self.num_rcpt * ssn.N,).\n",
    "        \"\"\"\n",
    "        #total input to power law I/O is the sum of currents of different types:\n",
    "        r = self.powlaw( v.reshape((self.num_rcpt, self.N)).sum(axis=0) )  ##QUESTION 3 - WHY NOT INPUT VEC IN POWER LAW\n",
    "        return ( -v + self.Wrcpt @ r + inp_vec ) / self.tau_s_vec\n",
    "\n",
    "    def dxdt(self, x, inp_vec):\n",
    "        return self.dvdt(x, inp_vec)\n",
    "\n",
    "    def DCjacobian(self, r):\n",
    "        \"\"\"\n",
    "        DC Jacobian (i.e. zero-frequency linear response) for\n",
    "        linearization around state-vector v, leading to rate-vector r\n",
    "        \"\"\"\n",
    "        Phi = self.gains_from_r(r)\n",
    "        return ( -np.eye(self.num_rcpt * self.N) +\n",
    "                np.tile( self.Wrcpt * Phi[None,:] , (1, self.num_rcpt)) ) # broadcasting so that gain (Phi) varies by 2nd (presynaptic) neural index, and does not depend on receptor type or post-synaptic (1st) neural index\n",
    "\n",
    "\n",
    "    def linear_power_spect(self, r_fp, noise_pars, freq_range, fnums, e_LFP,\n",
    "                               gamma_range=[20,100], EIGS=False, EIGVECS=False):\n",
    "        \"\"\"\n",
    "        Returns the power spectrum/a (PS) of \"LFP\" recorded on 1 or MULTIPLE\n",
    "        \"electrodes\" or probes, in the noise-driven multi-synaptic SSN, in a\n",
    "        SINGLE stimulus condition, by linearizing in noise around the noise-free\n",
    "        fixed point for that stimulus. (The stimulus condition is specified\n",
    "        by its fixed point \"r_fp\".)\n",
    "        LFP is approximated as the total-input into neurons, averaged over a\n",
    "        group of neurons according to columns of \"e_LFP\" which provide the\n",
    "        averaging weights. Different columns of \"e_LFP\" correspond to different\n",
    "        probes. Averaging would be accurate if all column-sums of e_LFP are 1.\n",
    "        Also, since electrophysiologically, LFP corresponds to averaged input\n",
    "        to Pyramidal cells, it's more biological if e_LFP is only zero\n",
    "        on inhibitory rows.\n",
    "        Other inputs:\n",
    "        freq_range: two-element seq, specifying min and max freq's (in Hz)\n",
    "                    over which PS is calculated.\n",
    "        fnums: number of frequency grid-points to evaluate PS on in above range.\n",
    "        gamma_range: min and max freq's (in Hz) of gamma-range, used for\n",
    "                     calcualting total gamma power(s).\n",
    "        e_LFP: shape = (N, n_probes), with each N-dim column being the projection\n",
    "               or signature vector for a single LFP probe\n",
    "        EIGS: if True, the dynamical Jacobian and its eigenvalues at \"r_fp\" are\n",
    "              calculated.\n",
    "        noise_pars: specifies parameters of noise. Following fields are used\n",
    "                    (example values are what I had used for the SSNHomogRing model):\n",
    "                noise_pars.stdevE = 1.5; Std of E noise\n",
    "                noise_pars.stdevI = 1.5; Std of E noise\n",
    "                noise_pars.corr_time = 5; correlation time of noise in ms\n",
    "                noise_pars.corr_length = 0.5; correlation length of noise in angles; 0 doesn't work well..: too small response\n",
    "                noise_pars.NMDAratio = 0; % of external noise fed to the NMDA channel (the rest goes to AMPA)\n",
    "        example usage:\n",
    "        powspecs = ssn.linear_power_spect(r_fp, high_levels.NoisePars(), freq_range=[10,100], fnums=50, e_LFP)\n",
    "        # where powspecs.shape = (e_LFP.shape[1], fnums) or, if e_LFP.ndims==1, (fnums,).\n",
    "        \"\"\"\n",
    "        noise_sigsq, spatl_filt = self.make_noise_cov(noise_pars)\n",
    "        tau_corr = noise_pars.corr_time  /1000 # convert to seconds\n",
    "        noiseNMDA = 0 if self.num_rcpt<3 else noise_pars.NMDAratio\n",
    "        tau_s = np.diag(self.tau_s_vec) /1000 # convert to seconds\n",
    "\n",
    "        J = self.DCjacobian(r_fp)\n",
    "\n",
    "        ones_rcpt = np.ones(self.num_rcpt)\n",
    "        if e_LFP.ndim > 1 and e_LFP.shape[1] > 1:  # case of many different LFP probes (stacked along 2nd axis of e_LFP)\n",
    "            ones_rcpt = ones_rcpt[:, None]\n",
    "            noise_sigsq = noise_sigsq[:, None]\n",
    "        e_LFP1 = np.kron(ones_rcpt, e_LFP) # this tensor product by ones(...) is because of the unweighted sum of currents of different types inside the neuronal nonlinearity\n",
    "\n",
    "        # calculate LFP power spectrum/a:\n",
    "        fs = np.linspace(*freq_range,fnums) # grid of frequencies in Hz\n",
    "\n",
    "        ws = 2*np.pi * fs # angular freq's (omega's) in Hz\n",
    "        LFP_spectra = []\n",
    "        for w in ws:\n",
    "            vecE = np.linalg.solve( (-1j*w * tau_s - J).T.conj() , e_LFP1) # self.inv_G(w,J).T.conj() @ e_LFP1\n",
    "\n",
    "            # ASSUME noise is only coming thru AMPA and NMDA channels (first and last N inds, resp)\n",
    "            # AND both channels get same exact realization of noise, up to scaling (so noise cov is rank-deficient, with rank ssn.N instead of ssn.dim)\n",
    "            vecE1 = (1-noiseNMDA) * vecE[:self.N]  + noiseNMDA * vecE[-self.N:]\n",
    "            # account for spatial correlations in noise input\n",
    "            if spatl_filt.size > 1:\n",
    "                vecE = spatl_filt.T  @ vecE1\n",
    "                vecE1 = vecE\n",
    "            # power-spec of pink noise with time-constant tau_corr and variance 1, which is 2*\\tau /abs(-i\\omega*\\tau + 1)^2 (FT of exp(-|t|/tau))\n",
    "            noise_spect = 2* tau_corr/np.abs(-1j*w * tau_corr + 1)**2 # in Hz^{-1}\n",
    "\n",
    "            LFP_spectra.append( np.sum(vecE1.conj() * (noise_sigsq * vecE1), axis=0) * noise_spect )\n",
    "\n",
    "        # *2 to combine (the symmetric) power across positive and negative freq's:\n",
    "        LFP_spectra = 2 * np.real(np.asarray(LFP_spectra))\n",
    "\n",
    "        # calculate gamma power(s)\n",
    "        df = fs[1]-fs[0]\n",
    "        gamma_powers = np.sum(LFP_spectra[(gamma_range[0]<fs) & (fs<gamma_range[1])], axis=0) * df\n",
    "\n",
    "        # calculate Jacobian and its eigenvalues\n",
    "        if EIGS:\n",
    "            Jacob = self.jacobian(J) # np.kron(1/self.tau_s, np.ones(self.N))[:,None] * J  # equivalent to diag(tau_s) J (math)\n",
    "            if EIGVECS:\n",
    "                JacobLams = np.linalg.eig(Jacob)\n",
    "            else:\n",
    "                JacobLams = np.linalg.eigvals(Jacob)\n",
    "        else:\n",
    "            Jacob = JacobLams = None\n",
    "\n",
    "        return LFP_spectra.T, fs, gamma_powers, JacobLams, Jacob\n",
    "\n",
    "        # # using numba compiled code:\n",
    "        # Jacob = None if not EIGS else self.jacobian(J) # np.kron(1/ssn.tau_s, np.ones(ssn.N))[:,None] * J  # equivalent to diag(tau_s) J (math)\n",
    "        # shp = (len(fs),) if e_LFP1.ndim == 1 else (len(fs), e_LFP1.shape[1])\n",
    "        # return SSN_power_spec.linear_power_spect_loop(self.N, fs, 0*1j + e_LFP1, shp,\n",
    "        #                         J, noise_sigsq, spatl_filt, noiseNMDA, tau_s,\n",
    "        #                         tau_corr, np.asarray(gamma_range), EIGS, 0*1j + Jacob)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4bb85c",
   "metadata": {},
   "source": [
    "SSN2DTOPOV1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f95be8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================== 2D topographic models ============================\n",
    "class SSN2DTopoV1(_SSN_Base):\n",
    "    _Lring = 180\n",
    "\n",
    "    def __init__(self, n, k, tauE, tauI, grid_pars, conn_pars, **kwargs):\n",
    "        Ni = Ne = grid_pars.gridsize_Nx**2\n",
    "        tau_vec = np.hstack([tauE * np.ones(Ne), tauI * np.ones(Ni)])\n",
    "\n",
    "        super(SSN2DTopoV1, self).__init__(n=n, k=k, Ne=Ne, Ni=Ni,\n",
    "                                    tau_vec=tau_vec, **kwargs)\n",
    "\n",
    "        self.grid_pars = grid_pars\n",
    "        self.conn_pars = conn_pars\n",
    "        self._make_maps(grid_pars)\n",
    "        if conn_pars is not None: # conn_pars = None allows for ssn-object initialization without a W\n",
    "            self.make_W(**conn_pars)\n",
    "\n",
    "    @property\n",
    "    def neuron_params(self):\n",
    "        return dict(n=self.n, k=self.k,\n",
    "                    tauE=self.tau_vec[0], tauI=self.tau_vec[self.Ne])\n",
    "    @property\n",
    "    def maps_vec(self):\n",
    "        return np.vstack([self.x_vec, self.y_vec, self.ori_vec]).T\n",
    "\n",
    "    @property\n",
    "    def center_inds(self):\n",
    "        \"\"\" indices of center-E and center-I neurons \"\"\"\n",
    "        return np.where((self.x_vec==0) & (self.y_vec==0))[0]\n",
    "\n",
    "    @property\n",
    "    def x_vec_degs(self):\n",
    "        return self.x_vec / self.grid_pars.magnif_factor\n",
    "\n",
    "    @property\n",
    "    def y_vec_degs(self):\n",
    "        return self.y_vec / self.grid_pars.magnif_factor\n",
    "\n",
    "    def xys2inds(self, xys=[[0,0]], units=\"degree\"):\n",
    "        \"\"\"\n",
    "        indices of E and I neurons at location (x,y) (by default in degrees).\n",
    "        In:\n",
    "            xys: array-like list of xy coordinates.\n",
    "            units: specifies unit for xys. By default, \"degree\" of visual angle.\n",
    "        Out:\n",
    "            inds: shape = (2, len(xys)), inds[0] = vector-indices of E neurons\n",
    "                                         inds[1] = vector-indices of I neurons\n",
    "        \"\"\"\n",
    "        inds = []\n",
    "        for xy in xys:\n",
    "            if units == \"degree\": # convert to mm\n",
    "                xy = self.grid_pars.magnif_factor * np.asarray(xy)\n",
    "            distsq = (self.x_vec - xy[0])**2 + (self.y_vec - xy[1])**2\n",
    "            inds.append([np.argmin(distsq[:self.Ne]), self.Ne + np.argmin(distsq[self.Ne:])])\n",
    "        return np.asarray(inds).T\n",
    "\n",
    "    def xys2Emapinds(self, xys=[[0,0]], units=\"degree\"):\n",
    "        \"\"\"\n",
    "        (i,j) of E neurons at location (x,y) (by default in degrees). ##QUESTION 4 - i,j of a neuron?\n",
    "        In:\n",
    "            xys: array-like list of xy coordinates.\n",
    "            units: specifies unit for xys. By default, \"degree\" of visual angle.\n",
    "        Out:\n",
    "            map_inds: shape = (2, len(xys)), inds[0] = row_indices of E neurons in map\n",
    "                                         inds[1] = column-indices of E neurons in map\n",
    "        \"\"\"\n",
    "        vecind2mapind = lambda i: np.array([i % self.grid_pars.gridsize_Nx,\n",
    "                                            i // self.grid_pars.gridsize_Nx])\n",
    "        return vecind2mapind(self.xys2inds(xys)[0])\n",
    "\n",
    "    def vec2map(self, vec):\n",
    "        assert vec.ndim == 1\n",
    "        Nx = self.grid_pars.gridsize_Nx\n",
    "        if len(vec) == self.Ne:\n",
    "            map = np.reshape(vec, (Nx, Nx))\n",
    "        elif len(vec) == self.N:\n",
    "            map = (np.reshape(vec[:self.Ne], (Nx, Nx)),\n",
    "                   np.reshape(vec[self.Ne:], (Nx, Nx)))\n",
    "        return map\n",
    "\n",
    "    def _make_maps(self, grid_pars=None):\n",
    "        if grid_pars is None:\n",
    "            grid_pars = self.grid_pars\n",
    "        else:\n",
    "            self.grid_pars = grid_pars\n",
    "\n",
    "        self._make_retinmap()\n",
    "        self._make_orimap()\n",
    "\n",
    "        return self.x_map, self.y_map, self.ori_map\n",
    "\n",
    "    def _make_retinmap(self, grid_pars=None):\n",
    "        \"\"\"\n",
    "        make square grid of locations with X and Y retinotopic maps\n",
    "        \"\"\"\n",
    "        if grid_pars is None:\n",
    "            grid_pars = self.grid_pars\n",
    "        else:\n",
    "            self.grid_pars = grid_pars\n",
    "        if not hasattr(grid_pars, \"gridsize_mm\"):\n",
    "            self.grid_pars.gridsize_mm = grid_pars.gridsize_deg * grid_pars.magnif_factor\n",
    "        Lx = Ly = self.grid_pars.gridsize_mm\n",
    "        Nx = Ny = grid_pars.gridsize_Nx\n",
    "        dx = dy = Lx/(Nx - 1)\n",
    "        self.grid_pars.dx = dx # in mm\n",
    "        self.grid_pars.dy = dy # in mm\n",
    "\n",
    "        xs = np.linspace(0, Lx, Nx)\n",
    "        ys = np.linspace(0, Ly, Ny)\n",
    "        [X, Y] = np.meshgrid(xs - xs[len(xs)//2], ys - ys[len(ys)//2]) # doing it this way, as opposed to using np.linspace(-Lx/2, Lx/2, Nx) (for which this fails for even Nx), guarantees that there is always a pixel with x or y == 0\n",
    "        Y = -Y # without this Y decreases going upwards\n",
    "\n",
    "        self.x_map = X\n",
    "        self.y_map = Y\n",
    "        self.x_vec = np.tile(X.ravel(), (2,))\n",
    "        self.y_vec = np.tile(Y.ravel(), (2,))\n",
    "        return self.x_map, self.y_map\n",
    "\n",
    "    def _make_orimap(self, hyper_col=None, nn=30, X=None, Y=None):\n",
    "        '''\n",
    "        Makes the orientation map for the grid, by superposition of plane-waves. ##QUESTIUON 5 - superposition?\n",
    "        hyper_col = hyper column length for the network in retinotopic degrees\n",
    "        nn = (30 by default) # of planewaves used to construct the map\n",
    "\n",
    "        Outputs/side-effects:\n",
    "        OMap = self.ori_map = orientation preference for each cell in the network\n",
    "        self.ori_vec = vectorized OMap\n",
    "        '''\n",
    "        if hyper_col is None:\n",
    "             hyper_col = self.grid_pars.hyper_col\n",
    "        else:\n",
    "             self.grid_pars.hyper_col = hyper_col\n",
    "        X = self.x_map if X is None else X\n",
    "        Y = self.y_map if Y is None else Y\n",
    "\n",
    "        z = np.zeros_like(X)\n",
    "        for j in range(nn):\n",
    "            kj = np.array([np.cos(j * np.pi/nn), np.sin(j * np.pi/nn)]) * 2*np.pi/(hyper_col)\n",
    "            \n",
    "            ## JAX CHANGES ##\n",
    "            key = random.PRNGKey(87)\n",
    "            key, subkey = random.split(key)\n",
    "            sj = 2 *random.randint(key=key, shape=[1,1], minval=0, maxval=2)-1 #random number that's either + or -1.\n",
    "            key, subkey = random.split(key)\n",
    "            phij = random.uniform(key, shape=[1,1], minval=0, maxval=1)*2*np.pi\n",
    "\n",
    "            tmp = (X*kj[0] + Y*kj[1]) * sj + phij\n",
    "            z = z + np.exp(1j * tmp)\n",
    "\n",
    "        # ori map with preferred orientations in the range (0, _Lring] (i.e. (0, 180] by default)\n",
    "        self.ori_map = (np.angle(z) + np.pi) * SSN2DTopoV1._Lring/(2*np.pi)\n",
    "        # #for debugging/testing:\n",
    "        # self.ori_map = 180 * (self.y_map - self.y_map.min())/(self.y_map.max() - self.y_map.min())\n",
    "        # self.ori_map[self.ori_map.shape[0]//2+1:,:] = 180\n",
    "        self.ori_vec = np.tile(self.ori_map.ravel(), (2,))\n",
    "        return self.ori_map\n",
    "\n",
    "    def _make_distances(self, PERIODIC):\n",
    "        Lx = Ly = self.grid_pars.gridsize_mm\n",
    "        absdiff_ring = lambda d_x, L: np.minimum(np.abs(d_x), L - np.abs(d_x))\n",
    "        if PERIODIC:\n",
    "            absdiff_x = absdiff_y = lambda d_x: absdiff_ring(d_x, Lx + self.grid_pars.dx)\n",
    "        else:\n",
    "            absdiff_x = absdiff_y = lambda d_x: np.abs(d_x)\n",
    "        xs = np.reshape(self.x_vec, (2, self.Ne, 1)) # (cell-type, grid-location, None)\n",
    "        ys = np.reshape(self.y_vec, (2, self.Ne, 1)) # (cell-type, grid-location, None)\n",
    "        oris = np.reshape(self.ori_vec, (2, self.Ne, 1)) # (cell-type, grid-location, None)\n",
    "        # to generalize the next two lines, can replace 0's with a and b in range(2) (pre and post-synaptic cell-type indices)\n",
    "        xy_dist = np.sqrt(absdiff_x(xs[0] - xs[0].T)**2 + absdiff_y(ys[0] - ys[0].T)**2)\n",
    "        ori_dist = absdiff_ring(oris[0] - oris[0].T, SSN2DTopoV1._Lring)\n",
    "        self.xy_dist = xy_dist\n",
    "        self.ori_dist = ori_dist\n",
    "\n",
    "        return xy_dist, ori_dist  ##QUESTION 5 - what distances, what is 9*9 (x_map, y_map, ori_map)\n",
    "\n",
    "    \n",
    "    def make_W(self, J_2x2, s_2x2, p_local, sigma_oris=45, Jnoise=0,\n",
    "                Jnoise_GAUSSIAN=True, MinSyn=1e-4, CellWiseNormalized=True,\n",
    "                                                    PERIODIC=True): #, prngKey=0):\n",
    "        \"\"\"\n",
    "        make the full recurrent connectivity matrix W\n",
    "        In:\n",
    "         J_2x2 = total strength of weights of different pre/post cell-type\n",
    "         s_2x2 = ranges of weights between different pre/post cell-type\n",
    "         p_local = relative strength of local parts of E projections\n",
    "         sigma_oris = range of wights in terms of preferred orientation difference\n",
    "\n",
    "        Output/side-effects:\n",
    "        self.W\n",
    "        \"\"\"\n",
    "        conn_pars = locals()\n",
    "        conn_pars.pop(\"self\")\n",
    "        self.conn_pars = conn_pars\n",
    "\n",
    "        if hasattr(self, \"xy_dist\") and hasattr(self, \"ori_dist\"):\n",
    "            xy_dist = self.xy_dist\n",
    "            ori_dist = self.ori_dist\n",
    "        else:\n",
    "            xy_dist, ori_dist = self._make_distances(PERIODIC)\n",
    "\n",
    "        if np.isscalar(sigma_oris): sigma_oris = sigma_oris * np.ones((2,2))\n",
    "\n",
    "        if np.isscalar(p_local) or len(p_local) == 1:\n",
    "            p_local = np.asarray(p_local) * np.ones(2)\n",
    "\n",
    "        Wblks = [[1,1],[1,1]]\n",
    "        # loop over post- (a) and pre-synaptic (b) cell-types\n",
    "        for a in range(2):\n",
    "            for b in range(2):\n",
    "                if b == 0: # E projections\n",
    "                    W = np.exp(-xy_dist/s_2x2[a,b] -ori_dist**2/(2*sigma_oris[a,b]**2))\n",
    "                elif b == 1: # I projections\n",
    "                    W = np.exp(-xy_dist**2/(2*s_2x2[a,b]**2) -ori_dist**2/(2*sigma_oris[a,b]**2))\n",
    "\n",
    "                if Jnoise > 0: # add some noise\n",
    "                    if Jnoise_GAUSSIAN:\n",
    "                        ##JAX CHANGES##\n",
    "                        #jitter = np.random.standard_normal(W.shape)\n",
    "                        key = random.PRNGKey(87)\n",
    "                        key, subkey=random.split(key)\n",
    "                        jitter = random.normal(key, W.shape)\n",
    "                    else:\n",
    "                        ##JAX CHANGES##\n",
    "                       #jitter = 2* np.random.random(W.shape) - 1\n",
    "                        key = random.PRNGKey(87)\n",
    "                        key, subkey=random.split(key)\n",
    "                        jitter = 2* random.uniform(key, W.shape) - 1\n",
    "                    W = (1 + Jnoise * jitter) * W\n",
    "\n",
    "                # sparsify (set small weights to zero)\n",
    "                W = np.where(W < MinSyn, 0, W) # what's the point of this if not using sparse matrices\n",
    "\n",
    "                # row-wise normalize\n",
    "                tW = np.sum(W, axis=1)\n",
    "                if not CellWiseNormalized:\n",
    "                    tW = np.mean(tW)\n",
    "                W = W / tW\n",
    "\n",
    "                # for E projections, add the local part\n",
    "                # NOTE: alterntaively could do this before adding noise & normalizing\n",
    "                if b == 0:\n",
    "                    W = p_local[a] * np.eye(*W.shape) + (1-p_local[a]) * W\n",
    "\n",
    "                Wblks[a][b] = J_2x2[a, b] * W\n",
    "\n",
    "        self.W = np.block(Wblks)\n",
    "        return self.W\n",
    "\n",
    "    def _make_inp_ori_dep(self, ONLY_E=False, ori_s=None, sig_ori_EF=32, sig_ori_IF=None, gE=1, gI=1):\n",
    "        \"\"\"\n",
    "        makes the orintation dependence factor for grating or Gabor stimuli\n",
    "        (a la Ray & Maunsell 2010)\n",
    "        \"\"\"\n",
    "        if ori_s is None:  # set stim ori to pref ori of grid center E cell (same as I cell)\n",
    "            ##JAX CHANGES##\n",
    "            #ori_s = self.ori_vec[(self.x_vec==0) & (self.y_vec==0) & (self.EI==b\"E\")]\n",
    "            ori_s = self.ori_vec[(self.x_vec==0) & (self.y_vec==0) & self.condition]\n",
    "        if sig_ori_IF is None:\n",
    "            sig_ori_IF = sig_ori_EF\n",
    "\n",
    "        distsq = lambda x: np.minimum(np.abs(x), SSN2DTopoV1._Lring - np.abs(x))**2\n",
    "        dori = self.ori_vec - ori_s\n",
    "        if not ONLY_E:\n",
    "            ori_fac = np.hstack((gE * np.exp(-distsq(dori[:self.Ne])/(2* sig_ori_EF**2)),\n",
    "                                 gI * np.exp(-distsq(dori[self.Ne:])/(2* sig_ori_IF**2))))\n",
    "        else:\n",
    "            ori_fac = gE * np.exp(-distsq(dori[:self.Ne])/(2* sig_ori_EF**2))\n",
    "\n",
    "        return ori_fac\n",
    "\n",
    "    def make_grating_input(self, radius_s, sigma_RF=0.4, ONLY_E=False,\n",
    "            ori_s=None, sig_ori_EF=32, sig_ori_IF=None, gE=1, gI=1, contrast=1):\n",
    "        \"\"\"\n",
    "        make grating external input centered on the grid-center, with radius \"radius\",\n",
    "        with edge-fall-off scale \"sigma_RF\", with orientation \"ori_s\",\n",
    "        with the orientation tuning-width of E and I parts given by \"sig_ori_EF\"\n",
    "        and \"sig_ori_IF\", respectively, and with amplitue (maximum) of the E and I parts,\n",
    "        given by \"contrast * gE\" and \"contrast * gI\", respectively.\n",
    "        If ONLY_E=True, it only makes the E-part of the input vector.\n",
    "        \"\"\"\n",
    "        # make the orintation dependence factor:\n",
    "        ori_fac = self._make_inp_ori_dep(ONLY_E, ori_s, sig_ori_EF, sig_ori_IF, gE, gI)\n",
    "\n",
    "        # make the spatial envelope:\n",
    "        sigmoid = lambda x: 1/(1 + np.exp(-x))\n",
    "        M = self.Ne if ONLY_E else self.N\n",
    "        r_vec = np.sqrt(self.x_vec_degs[:M]**2 + self.y_vec_degs[:M]**2)\n",
    "        spat_fac = sigmoid((radius_s - r_vec)/sigma_RF)\n",
    "\n",
    "        return contrast * ori_fac * spat_fac\n",
    "\n",
    "    def make_gabor_input(self, sigma_Gabor=0.5, ONLY_E=False,\n",
    "            ori_s=None, sig_ori_EF=32, sig_ori_IF=None, gE=1, gI=1, contrast=1):\n",
    "        \"\"\"\n",
    "        make the Gabor stimulus (a la Ray & Maunsell 2010) centered on the\n",
    "        grid-center, with sigma \"sigma_Gabor\",\n",
    "        with orientation \"ori_s\",\n",
    "        with the orientation tuning-width of E and I parts given by \"sig_ori_EF\"\n",
    "        and \"sig_ori_IF\", respectively, and with amplitue (maximum) of the E and I parts,\n",
    "        given by \"contrast * gE\" and \"contrast * gI\", respectively.\n",
    "        \"\"\"\n",
    "        # make the orintation dependence factor:\n",
    "        ori_fac = self._make_inp_ori_dep(ONLY_E, ori_s, sig_ori_EF, sig_ori_IF, gE, gI)\n",
    "\n",
    "        # make the spatial envelope:\n",
    "        gaussian = lambda x: np.exp(- x**2 / 2)\n",
    "        M = self.Ne if ONLY_E else self.N\n",
    "        r_vec = np.sqrt(self.x_vec_degs[:M]**2 + self.y_vec_degs[:M]**2)\n",
    "        spat_fac = gaussian(r_vec/sigma_Gabor)\n",
    "\n",
    "        return contrast * ori_fac * spat_fac\n",
    "\n",
    "    # TODO:\n",
    "    # def make_noise_cov(self, noise_pars):\n",
    "    #     # the script assumes independent noise to E and I, and spatially uniform magnitude of noise\n",
    "    #     noise_sigsq = np.hstack( (noise_pars.stdevE**2 * np.ones(self.Ne),\n",
    "    #                            noise_pars.stdevI**2 * np.ones(self.Ni)) )\n",
    "    #\n",
    "    #     spatl_filt = ...\n",
    "\n",
    "    def make_eLFP_from_inds(self, LFPinds):\n",
    "        \"\"\"\n",
    "        makes a single LFP electrode signature (normalized spatial weight\n",
    "        profile), given the (vectorized) indices of recorded neurons (LFPinds).\n",
    "\n",
    "        OUT: e_LFP with shape (self.N,)\n",
    "        \"\"\"\n",
    "        # LFPinds was called LFPrange in my MATLAB code\n",
    "        if LFPinds is None:\n",
    "            LFPinds = [0]\n",
    "        e_LFP = 1/len(LFPinds) * np.isin(np.arange(self.N), LFPinds) # assuming elements of LFPinds are all smaller than self.Ne, e_LFP will only have 1's on E elements\n",
    "        # eI = 1/len(LFPinds) * np.isin(np.arange(self.N) - self.Ne, LFPinds) # assuming elements of LFPinds are all smaller than self.Ne, e_LFP will only have 1's on I elements\n",
    "\n",
    "        return e_LFP\n",
    "\n",
    "    def make_eLFP_from_xy(self, probe_xys, LFPradius=0.2, unit_xys=\"degree\", unit_rad=\"mm\"):\n",
    "        \"\"\"\n",
    "        makes 1 or multiple LFP electrodes signatures (normalized spatial weight\n",
    "        profile over E cells), given the (x,y) retinotopic coordinates of LFP probes.\n",
    "\n",
    "        IN: probe_xys: shape (#probes, 2). Each row is the (x,y) coordinates of\n",
    "                 a probe/electrode (by default given in degrees of visual angle)\n",
    "             LFPradius: positive scalar. radius/range of LFP (by default given in mm)\n",
    "            unit_xys: either \"degree\" or \"mm\", unit of LFP_xys\n",
    "            unit_rad: either \"degree\" or \"mm\", unit of LFPradius\n",
    "        OUT: e_LFP: shape (self.N, #probes) = (self.N, LFP.xys.shape[0])\n",
    "             Each column is the normalized spatial profile of one probe.\n",
    "        \"\"\"\n",
    "        if unit_rad == \"degree\":\n",
    "            LFPradius = self.grid_pars.magnif_factor * LFPradius\n",
    "\n",
    "        e_LFP = []\n",
    "        for xy in probe_xys:\n",
    "            if unit_xys == \"degree\": # convert to mm\n",
    "                xy = self.grid_pars.magnif_factor * np.asarray(xy)\n",
    "            e_LFP.append(1.0 * ( (self.EI == b\"E\") &\n",
    "            (LFPradius**2 > (self.x_vec - xy[0])**2 + (self.y_vec - xy[1])**2)))\n",
    "\n",
    "        return np.asarray(e_LFP).T\n",
    "\n",
    "\n",
    "\n",
    "class SSN2DTopoV1_AMPAGABA(SSN2DTopoV1, _SSN_AMPAGABA_Base):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873aa5cb",
   "metadata": {},
   "source": [
    "### Common parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "905a1aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "class ssn_pars():\n",
    "    n = 2\n",
    "    k = 0.04\n",
    "    tauE = 30 # in ms\n",
    "    tauI = 10 # in ms\n",
    "    psi = 0.774\n",
    "    tau_s = np.array([5, 7, 100]) #in ms, AMPA, GABA, NMDA current decay time constants\n",
    "    make_J2x2 = lambda Jee, Jei, Jie, Jii: np.array([[Jee, -Jei], [Jie,  -Jii]]) * np.pi * ssn_pars.psi\n",
    "\n",
    "# with mm_scale=1, The following match \"fixed_params\" of  'Fig4_data-retinoHists-samples1000_TauCorr5_2020-04-11.json'\n",
    "class grid_pars():\n",
    "    gridsize_Nx = 8 + 1 # grid-points across each edge # gives rise to dx = 0.8 mm\n",
    "    gridsize_deg = 2 * 1.6 # edge length in degrees\n",
    "    magnif_factor = 2  # mm/deg\n",
    "    hyper_col = 0.8 # mm   \n",
    "    sigma_RF = 0.4 # deg (visual angle)\n",
    "\n",
    "# Caleb's params for the full (with local) model:\n",
    "Js0 = [1.82650658, 0.68194475, 2.06815311, 0.5106321]\n",
    "gE, gI = 0.57328625, 0.26144141\n",
    "sigEE, sigIE = 0.2, 0.40\n",
    "sigEI, sigII = .09, .09\n",
    "conn_pars = dict(\n",
    "    PERIODIC = False,\n",
    "    J_2x2 = ssn_pars.make_J2x2(*Js0),\n",
    "    s_2x2 = np.array([[sigEE, sigEI],[sigIE, sigII]]), # in mm\n",
    "    p_local = [.4, 0.7], # [p_local_EE, p_local_IE],\n",
    "    sigma_oris = 1000)  # sigma_oris\n",
    "conn_pars['J_2x2'] = ssn_pars.make_J2x2(*Js0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb5a4be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ssn = SSN_classes.SSN2DTopoV1_AMPAGABA(ssn_pars.n, ssn_pars.k, ssn_pars.tauE, ssn_pars.tauI, grid_pars, conn_pars=conn_pars, tau_s=ssn_pars.tau_s)\n",
    "ssn = SSN2DTopoV1_AMPAGABA(ssn_pars.n, ssn_pars.k, ssn_pars.tauE,\n",
    "              ssn_pars.tauI, grid_pars, conn_pars=conn_pars, tau_s=ssn_pars.tau_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121d9e18",
   "metadata": {},
   "source": [
    "## Study 1: FC histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8e86384",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntrials = 1000\n",
    "\n",
    "GABA_facs = np.linspace(1.0, .75, 2) * 2.6\n",
    "excitabs = np.array([1, 1.]) * 0\n",
    "I2Eexcit = 0;\n",
    "spont_input = np.array([1,1]) * 3\n",
    "\n",
    "contrast = 50\n",
    "grid_pars.sig_ori_EF = 32 # deg (ori)\n",
    "\n",
    "lcorr_noise_grid = 2.6\n",
    "rel_sigma_noise = 0.2\n",
    "sigma_noise = .2 # rel_sigma_noise * contrast\n",
    "I2E_noise = 2\n",
    "\n",
    "dt = 1\n",
    "xtol = 1e-5\n",
    "Tmax = 200\n",
    "\n",
    "utri = lambda x: x.flatten()[(np.arange(x.shape[0])[None,:] > np.arange(x.shape[0])[:,None]).flatten()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cba26e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssn = SSN2DTopoV1_AMPAGABA(ssn_pars.n, ssn_pars.k, ssn_pars.tauE,\n",
    "              ssn_pars.tauI, grid_pars, conn_pars=conn_pars, tau_s=ssn_pars.tau_s)\n",
    "\n",
    "inp0 = contrast * ssn.make_grating_input(radius_s=grid_pars.gridsize_deg * 5, sigma_RF=grid_pars.sigma_RF,\n",
    "                                sig_ori_EF=grid_pars.sig_ori_EF, gE=gE, gI=gI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8006fbae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GABA = 2.6:   0%|                                                                              | 0/1000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'make_noise' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [24], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m rsE \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tr \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(Ntrials), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGABA = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfac\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 17\u001b[0m     inp \u001b[38;5;241m=\u001b[39m inp0 \u001b[38;5;241m+\u001b[39m make_noise(sigma_noise, lcorr_noise_grid, ssn, I2E_noise) \\\n\u001b[1;32m     18\u001b[0m                \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mkron(spont_input \u001b[38;5;241m+\u001b[39m dc \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m1\u001b[39m,I2Eexcit]), np\u001b[38;5;241m.\u001b[39mones(ssn\u001b[38;5;241m.\u001b[39mNe))\n\u001b[1;32m     19\u001b[0m     r_fps, CONVG \u001b[38;5;241m=\u001b[39m ssn\u001b[38;5;241m.\u001b[39mfixed_point_r(inp, r_init\u001b[38;5;241m=\u001b[39mr_init, Tmax\u001b[38;5;241m=\u001b[39mTmax, dt\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, xtol\u001b[38;5;241m=\u001b[39mxtol, silent\u001b[38;5;241m=\u001b[39msilent_fp)\n\u001b[1;32m     20\u001b[0m     rsE\u001b[38;5;241m.\u001b[39mappend(r_fps[:ssn\u001b[38;5;241m.\u001b[39mNe])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'make_noise' is not defined"
     ]
    }
   ],
   "source": [
    "ssn = SSN2DTopoV1_AMPAGABA(ssn_pars.n, ssn_pars.k, ssn_pars.tauE,\n",
    "              ssn_pars.tauI, grid_pars, conn_pars=conn_pars, tau_s=ssn_pars.tau_s)\n",
    "\n",
    "inp0 = contrast * ssn.make_grating_input(radius_s=grid_pars.gridsize_deg * 5, sigma_RF=grid_pars.sigma_RF,\n",
    "                                 sig_ori_EF=grid_pars.sig_ori_EF, gE=gE, gI=gI)\n",
    "r_init = np.zeros(inp0.shape)\n",
    "\n",
    "silent_fp = True\n",
    "keys = [f\"GABA{j}\" for j in range(len(GABA_facs))]\n",
    "FC_E = {}\n",
    "for key, fac, dc in zip(keys, GABA_facs, excitabs):\n",
    "    conn_pars['J_2x2'] = ssn_pars.make_J2x2(*Js0) * np.array([1, fac]) * 20\n",
    "    ssn.make_W(**conn_pars)\n",
    "   \n",
    "    rsE = []\n",
    "    for tr in tqdm(range(Ntrials), desc=f\"GABA = {fac:.2}\"):\n",
    "        inp = inp0 + make_noise(sigma_noise, lcorr_noise_grid, ssn, I2E_noise) \\\n",
    "                   + np.kron(spont_input + dc * np.array([1,I2Eexcit]), np.ones(ssn.Ne))\n",
    "        r_fps, CONVG = ssn.fixed_point_r(inp, r_init=r_init, Tmax=Tmax, dt=1, xtol=xtol, silent=silent_fp)\n",
    "        rsE.append(r_fps[:ssn.Ne])\n",
    "    rsE = np.array(rsE).T # shape = (Ne, Ntrials)\n",
    "   \n",
    "    FC_E[key] = utri(np.corrcoef(rsE))\n",
    "   \n",
    "\n",
    "hist_color = [\"green\", \"orange\"]\n",
    "bins = 20\n",
    "histstyle = {\"histtype\": \"step\", \"linewidth\": 2.25, \"density\": False}\n",
    "histstyle_nb = {\"histtype\": \"bar\", \"linewidth\":2, \"alpha\": .3, \"density\": False}\n",
    "\n",
    "pv = stats.ttest_ind(FC_E[keys[0]], FC_E[keys[1]]).pvalue\n",
    "label = [\"1.0 x synaptic I\", \"0.9 x synaptic I\"]\n",
    "fig, ax = plt.subplots(1,1,figsize=np.array([6.4,4.8]))\n",
    "for g in range(len(keys)):\n",
    "    ax.hist(FC_E[keys[g]], bins=bins, color=hist_color[g], **histstyle)\n",
    "    ax.hist(FC_E[keys[g]], bins=bins, color=hist_color[g], **histstyle_nb, label=label[g])\n",
    "    ax.axvline(FC_E[keys[g]].mean(), color=hist_color[g], ls=\"--\")   \n",
    "    ax.legend(loc='upper left', fontsize=\"x-large\")\n",
    "    ax.text(.5, 300, f\"p = {pv:.2}\", fontsize=\"xx-large\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcde361",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
