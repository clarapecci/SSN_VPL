{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d354ebc",
   "metadata": {},
   "source": [
    "# 2D SSN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518b38e3",
   "metadata": {},
   "source": [
    "In this notebook:\n",
    "- training script for SSN model\n",
    "- implementation of vmap\n",
    "- new parameter added for extra synaptic GABA\n",
    "- storing accuracy and params in csv file\n",
    "- function to plot csv file data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5402589a",
   "metadata": {},
   "source": [
    "GPU jax issues\n",
    "- https://github.com/google/jax/issues/5231\n",
    "- https://catid.io/posts/jax/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adb6de8",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d27bfd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax backend cpu\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time, os, json\n",
    "import pandas as pd\n",
    "from scipy import stats \n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import jax\n",
    "from jax import random\n",
    "from jax.config import config \n",
    "import jax.numpy as np\n",
    "from jax import vmap\n",
    "import pdb\n",
    "import optax\n",
    "import csv\n",
    "import time\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy\n",
    "\n",
    "from jax.lib import xla_bridge\n",
    "print(\"jax backend {}\".format(xla_bridge.get_backend().platform))\n",
    "#config.update('jax_debug_nans', True)\n",
    "from SSN_classes_jax import SSN2DTopoV1_AMPAGABA_ONOFF\n",
    "from util import GaborFilter, BW_Grating, find_A, create_gabor_filters, create_gratings\n",
    "\n",
    "#initialize key\n",
    "key = random.PRNGKey(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1e1f5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.10\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7874579f",
   "metadata": {},
   "source": [
    "### Parameters to define"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993dd69f",
   "metadata": {},
   "source": [
    "1. STIMULI PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72234cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gabor parameters \n",
    "sigma_g= 0.5\n",
    "k = np.pi/(6*sigma_g)\n",
    "\n",
    "#Stimuli parameters\n",
    "ref_ori = 55\n",
    "offset = 5\n",
    "\n",
    "#Assemble parameters in dictionary\n",
    "general_pars = dict(k=k , edge_deg=3.2,  degree_per_pixel=0.05)\n",
    "stimuli_pars = dict(outer_radius=3, inner_radius=2.5, grating_contrast=0.8, std = 15, jitter_val = 5)\n",
    "stimuli_pars.update(general_pars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8497399e",
   "metadata": {},
   "source": [
    "2. MODEL PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3969cb36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([ 0.01629311, -0.1508426 , -0.02029357,  0.3664025 ,\n",
       "             -0.14365803,  0.48855314,  0.01699204,  0.06440228,\n",
       "             -0.28795138, -0.00203435, -0.03880432,  0.35099667,\n",
       "             -0.11369185, -0.04529791, -0.17772704,  0.10954434,\n",
       "              0.08752213, -0.3048131 , -0.3041017 , -0.23369014,\n",
       "             -0.00281296,  0.19054674, -0.22224793,  0.29554725,\n",
       "             -0.07371764], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Network parameters\n",
    "class ssn_pars():\n",
    "    n = 2\n",
    "    k = 0.04\n",
    "    tauE = 30 # in ms\n",
    "    tauI = 10 # in ms~\n",
    "    psi = 0.774\n",
    "    tau_s = np.array([5, 7, 100]) #in ms, AMPA, GABA, NMDA current decay time constants\n",
    "    \n",
    "\n",
    "#Grid parameters\n",
    "class grid_pars():\n",
    "    gridsize_Nx = 9 # grid-points across each edge # gives rise to dx = 0.8 mm\n",
    "    gridsize_deg = 2 * 1.6 # edge length in degrees\n",
    "    magnif_factor = 2  # mm/deg\n",
    "    hyper_col = 0.8 # mm   \n",
    "    sigma_RF = 0.4 # deg (visual angle)\n",
    "\n",
    "# Caleb's params for the full (with local) model:\n",
    "Js0 = [1.82650658, 0.68194475, 2.06815311, 0.5106321]\n",
    "gE, gI = 0.57328625, 0.26144141\n",
    "\n",
    "sigEE, sigIE = 0.2, 0.40\n",
    "#sigEI, sigII = .09, .09\n",
    "sigEI, sigII = .02, .02\n",
    "conn_pars = dict(\n",
    "    PERIODIC = False,\n",
    "    p_local = [.4, 0.7], # [p_local_EE, p_local_IE],\n",
    "    sigma_oris = 1000) # sigma_oris\n",
    "\n",
    "\n",
    "make_J2x2 = lambda Jee, Jei, Jie, Jii: np.array([[Jee, -Jei], [Jie,  -Jii]]) * np.pi * ssn_pars.psi\n",
    "J_2x2 = make_J2x2(*Js0)\n",
    "s_2x2 = np.array([[sigEE, sigEI],[sigIE, sigII]])\n",
    "\n",
    "#Parameters exclusive to Gabor filters\n",
    "filter_pars = dict(sigma_g = sigma_g, conv_factor = grid_pars.magnif_factor)\n",
    "filter_pars.update(general_pars) \n",
    "\n",
    "\n",
    "#Positive reparameterization\n",
    "signs=np.array([[1, -1], [1, -1]])\n",
    "logJ_2x2 =np.log(J_2x2*signs)\n",
    "logs_2x2 = np.log(s_2x2)\n",
    "\n",
    "\n",
    "#Excitatory and inhibitory constants for extra synaptic GABA\n",
    "ssn=SSN2DTopoV1_AMPAGABA_ONOFF(ssn_pars=ssn_pars, grid_pars=grid_pars, conn_pars=conn_pars, filter_pars=filter_pars, J_2x2=J_2x2, s_2x2=s_2x2)\n",
    "c_E = 5.0\n",
    "c_I = 5.0\n",
    "\n",
    "#Sigmoid parameters\n",
    "N_neurons = 25\n",
    "\n",
    "#key, _ = random.split(key)\n",
    "#w_sig = random.normal(key, shape = (N_neurons,)) / np.sqrt(N_neurons)\n",
    "w_sig = numpy.random.normal(size=(N_neurons,)) / np.sqrt(N_neurons)\n",
    "#w_sig = np.zeros((N_neurons))\n",
    "b_sig = 0.0\n",
    "\n",
    "#Optimization pars\n",
    "opt_pars = dict(logJ_2x2 = logJ_2x2, logs_2x2 = logs_2x2, w_sig = w_sig, b_sig=b_sig, c_E = c_E, c_I = c_I)\n",
    "\n",
    "#Convergence parameters\n",
    "conv_pars=dict(dt = 1, xtol = 1e-5, Tmax = 400, verbose=False, silent=True)\n",
    "w_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a51623d",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_pars['w_sig']= np.array([-0.04346744,  0.01270511, -0.19294111, -0.26384515,\n",
    "             -0.00649891, -0.03129453,  0.05759591,  0.00837358,\n",
    "             -0.22383411,  0.13397244, -0.06888205,  0.07446209,\n",
    "              0.15030052,  0.16201133, -0.24590972,  0.11345117,\n",
    "             -0.4198472 ,  0.00842749, -0.27746084, -0.01278699,\n",
    "              0.17754272,  0.10319261,  0.03774104, -0.0394661 ,\n",
    "             -0.14298135])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccde2f80",
   "metadata": {},
   "source": [
    "3. TRAINING PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cec589e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name of results csv\n",
    "home_dir = os.getcwd()\n",
    "#Create directory for results\n",
    "results_dir = os.path.join(home_dir, 'results')\n",
    "if os.path.exists(results_dir) == False:\n",
    "        os.makedirs(results_dir)\n",
    "        \n",
    "        \n",
    "results_name = 'sima_test4.csv' #SPECIFY NAME OF RESULTS FILE\n",
    "if results_name == None:\n",
    "    results_name = 'results_test2.csv'\n",
    "\n",
    "results_filename = os.path.join(results_dir, results_name)\n",
    "\n",
    "#Number of epochs\n",
    "epochs = 5\n",
    "num_epochs_to_save = 3\n",
    "epochs_to_save = np.linspace(1 ,epochs, num_epochs_to_save).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e78af46",
   "metadata": {},
   "source": [
    "## TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95fed975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(stimuli_pars, number=100, offset = 5, ref_ori=55):\n",
    "    \n",
    "    '''\n",
    "    Create data for given jitter and noise value for testing (not dataloader)\n",
    "    '''\n",
    "    data = create_gratings(ref_ori=ref_ori, number=number, offset=offset, **stimuli_pars)\n",
    "    train_data = next(iter(DataLoader(data, batch_size=len(data), shuffle=False)))\n",
    "    train_data['ref'] = train_data['ref'].numpy()\n",
    "    train_data['target'] = train_data['target'].numpy()\n",
    "    train_data['label'] = train_data['label'].numpy()\n",
    "    \n",
    "    return train_data\n",
    "\n",
    "\n",
    "def save_params_dict(opt_pars, accuracy, epoch ):\n",
    "    J_2x2, s_2x2 = exponentiate(opt_pars)\n",
    "     \n",
    "    save_params= dict(val_accuracy= accuracy, \n",
    "                J_EE= J_2x2[0,0], J_EI = J_2x2[0,1], \n",
    "                              J_IE = J_2x2[1,0], J_II = J_2x2[1,1], \n",
    "                s_EE= s_2x2[0,0], s_EI = s_2x2[0,1], \n",
    "                              s_IE = s_2x2[1,0], s_II = s_2x2[1,1],\n",
    "                c_E = opt_pars['c_E'], c_I = opt_pars['c_I'], \n",
    "                 epoch = epoch, w_sig = opt_pars['w_sig'], b_sig=opt_pars['b_sig'])\n",
    "    \n",
    "    return save_params\n",
    "\n",
    "def constant_to_vec(c_E, c_I):\n",
    "    \n",
    "    matrix_E = np.zeros((9,9))\n",
    "    matrix_E = matrix_E.at[2:7, 2:7].set(c_E)\n",
    "    vec_E = np.ravel(matrix_E)\n",
    "    \n",
    "    matrix_I = np.zeros((9,9))\n",
    "    matrix_I = matrix_I.at[2:7, 2:7].set(c_I)\n",
    "    vec_I = np.ravel(matrix_I)\n",
    "    \n",
    "    constant_vec = np.hstack((vec_E, vec_E, vec_I, vec_I))\n",
    "    return constant_vec\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(x))\n",
    "\n",
    "def binary_loss(n, x):\n",
    "    return - (n*np.log(x) + (1-n)*np.log(1-x))\n",
    "\n",
    "def exponentiate(opt_pars):\n",
    "    signs=np.array([[1, -1], [1, -1]]) \n",
    "    \n",
    "    J_2x2 =np.exp(opt_pars['logJ_2x2'])*signs\n",
    "    s_2x2 = np.exp(opt_pars['logs_2x2'])\n",
    "    \n",
    "    return J_2x2, s_2x2\n",
    "\n",
    "def our_max(x, beta=1):\n",
    "    max_val = np.log(np.sum(np.exp(x*beta)))/beta\n",
    "    return max_val\n",
    "\n",
    "def model(opt_pars, ssn_pars, grid_pars, conn_pars, train_data, filter_pars,  conv_pars, Rmax = 50, lam_1=1, lam_2=1):\n",
    "    \n",
    "    J_2x2, s_2x2 = exponentiate(opt_pars)\n",
    "    \n",
    "    #Initialise network\n",
    "    ssn=SSN2DTopoV1_AMPAGABA_ONOFF(ssn_pars=ssn_pars, grid_pars=grid_pars, conn_pars=conn_pars, filter_pars=filter_pars, J_2x2=J_2x2, s_2x2=s_2x2)\n",
    "    \n",
    "    #Create vector using extrasynaptic constants\n",
    "    constant_vector = constant_to_vec(opt_pars['c_E'], opt_pars['c_I'])\n",
    "    \n",
    "    #Apply Gabor filters to stimuli\n",
    "    output_ref=np.matmul(ssn.gabor_filters, train_data['ref']) + constant_vector\n",
    "    output_target=np.matmul(ssn.gabor_filters, train_data['target']) + constant_vector\n",
    "    \n",
    "    #Rectify output\n",
    "    SSN_input_ref=np.maximum(0, output_ref)\n",
    "    SSN_input_target=np.maximum(0, output_target)\n",
    "\n",
    "    #Input to SSN\n",
    "    r_init = np.zeros(SSN_input_ref.shape[0])\n",
    "\n",
    "    fp_ref, _, avg_dx_ref = ssn.fixed_point_r(SSN_input_ref, r_init=r_init, **conv_pars)\n",
    "    x_ref = ssn.apply_bounding_box(fp_ref, size=3.2)\n",
    "    r_max_ref = our_max(fp_ref)/Rmax \n",
    "    #rint('avg_dx ,', avg_dx_ref)\n",
    "    \n",
    "    fp_target, _, avg_dx_target = ssn.fixed_point_r(SSN_input_target, r_init=r_init, **conv_pars)\n",
    "    x_target = ssn.apply_bounding_box(fp_target, size=3.2)\n",
    "    r_max_target = our_max(fp_target)/Rmax\n",
    "    #rint('r_max' , r_max_ref)\n",
    "\n",
    "    #Apply sigmoid function - combine ref and target\n",
    "    x = sigmoid( np.dot(opt_pars['w_sig'], (x_ref.ravel() - x_target.ravel())) + opt_pars['b_sig'])\n",
    "\n",
    "    #Calculate binary cross entropy loss\n",
    "    loss=binary_loss(train_data['label'], x)\n",
    "    \n",
    "    mag=np.abs(loss)\n",
    "    loss = loss + (lam_1*(avg_dx_ref + avg_dx_target) + lam_2*(r_max_ref + r_max_target))*mag\n",
    "   \n",
    "    return loss\n",
    "\n",
    "\n",
    "def loss(opt_pars, ssn_pars, grid_pars, conn_pars, train_data, filter_pars,  conv_pars):\n",
    "    '''\n",
    "    Calculate parallelized loss for batch of data through vmap.\n",
    "    Output:\n",
    "        mean loss of all the input images\n",
    "    '''\n",
    "    \n",
    "    vmap_model = vmap(model, in_axes = ({'b_sig': None, 'c_E':None, 'c_I': None, 'logJ_2x2': None, 'logs_2x2': None, 'w_sig': None}, None, None, {'PERIODIC': None, 'p_local': [None, None], 'sigma_oris': None},  {'ref':0, 'target':0, 'label':0}, {'conv_factor': None, 'degree_per_pixel': None, 'edge_deg': None, 'k': None, 'sigma_g': None}, {'Tmax': None, 'dt': None, 'silent': None, 'verbose': None, 'xtol': None}) )                   \n",
    "    loss = np.sum(vmap_model(opt_pars, ssn_pars, grid_pars, conn_pars, train_data, filter_pars,  conv_pars))\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def eval_model(opt_pars, ssn_pars, grid_pars, conn_pars, test_data, filter_pars,  conv_pars):\n",
    "    \n",
    "    J_2x2, s_2x2 = exponentiate(opt_pars)\n",
    "    #Create vector using extrasynaptic constants\n",
    "    constant_vector = constant_to_vec(opt_pars['c_E'], opt_pars['c_I'])\n",
    "    \n",
    "    #Initialise network\n",
    "    ssn=SSN2DTopoV1_AMPAGABA_ONOFF(ssn_pars=ssn_pars, grid_pars=grid_pars, conn_pars=conn_pars, filter_pars=filter_pars, J_2x2=J_2x2, s_2x2=s_2x2)\n",
    "\n",
    "    #Apply Gabor filters to stimuli\n",
    "    output_ref=np.matmul(ssn.gabor_filters, test_data['ref']) + constant_vector\n",
    "    \n",
    "    output_target=np.matmul(ssn.gabor_filters, test_data['target']) + constant_vector\n",
    "\n",
    "    #Rectify output\n",
    "    SSN_input_ref=np.maximum(0, output_ref)\n",
    "    SSN_input_target=np.maximum(0, output_target)\n",
    "\n",
    "    #Input to SSN\n",
    "    r_init = np.zeros(SSN_input_ref.shape[0])\n",
    "\n",
    "    fp_ref, _, avg_dx_ref = ssn.fixed_point_r(SSN_input_ref, r_init=r_init, **conv_pars)\n",
    "    x_ref = ssn.apply_bounding_box(fp_ref, size=3.2)\n",
    "\n",
    "    fp_target, _, avg_dx_target = ssn.fixed_point_r(SSN_input_target, r_init=r_init, **conv_pars)\n",
    "    x_target = ssn.apply_bounding_box(fp_target, size=3.2)\n",
    "    \n",
    "    dot= np.dot(opt_pars['w_sig'], (x_ref.ravel() - x_target.ravel()))\n",
    "\n",
    "    #Apply sigmoid function - combine ref and target\n",
    "    x = sigmoid( np.dot(opt_pars['w_sig'], (x_ref.ravel() - x_target.ravel())) + opt_pars['b_sig'])\n",
    "    \n",
    "    #compare prediction to label\n",
    "    pred_label = np.round(x)\n",
    "\n",
    "    #Calculate binary cross entropy loss\n",
    "    loss=binary_loss(test_data['label'], x)\n",
    "    \n",
    "    return loss, pred_label, x\n",
    "\n",
    "\n",
    "def vmap_eval(opt_pars, ssn_pars, grid_pars, conn_pars, test_data, filter_pars,  conv_pars):\n",
    "    \n",
    "    eval_vmap = vmap(eval_model, in_axes = ({'b_sig': None,  'c_E':None, 'c_I': None,  'logJ_2x2': None, 'logs_2x2': None, 'w_sig': None}, None, None, {'PERIODIC': None, 'p_local': [None, None], 'sigma_oris': None},  {'ref':0, 'target':0, 'label':0}, {'conv_factor': None, 'degree_per_pixel': None, 'edge_deg': None, 'k': None, 'sigma_g': None}, {'Tmax': None, 'dt': None, 'silent': None, 'verbose': None, 'xtol': None}) )\n",
    "    losses, pred_labels, dots = eval_vmap(opt_pars, ssn_pars, grid_pars, conn_pars, test_data, filter_pars,  conv_pars)\n",
    "    \n",
    "    accuracy = np.sum(test_data['label'] == pred_labels)/len(test_data['label']) \n",
    "    \n",
    "    vmap_loss= np.mean(losses)\n",
    "    \n",
    "    return vmap_loss, accuracy, dots\n",
    "\n",
    "\n",
    "def train_SSN_vmap(opt_pars, ssn_pars, grid_pars, conn_pars, stimuli_pars, filter_pars, conv_pars, results_filename, epochs_to_save, batch_size=20, ref_ori = 55, offset = 5, epochs=1, eta=10e-4):\n",
    "    \n",
    "    #Initialize loss\n",
    "    val_loss_per_epoch = []\n",
    "    training_losses=[]\n",
    "    \n",
    "        \n",
    "    #Initialise optimizer\n",
    "    optimizer = optax.adam(eta)\n",
    "    opt_state = optimizer.init(opt_pars)\n",
    "    \n",
    "    #Define test data - no need to iterate\n",
    "    test_data = create_data(stimuli_pars, number = batch_size, offset = offset, ref_ori = ref_ori)\n",
    "    val_loss, accuracy, _= vmap_eval(opt_pars, ssn_pars, grid_pars, conn_pars, test_data, filter_pars,  conv_pars)\n",
    "    print('Before training  -- loss: {}, accuracy: {} '.format(val_loss, accuracy))\n",
    "    val_loss_per_epoch.append(val_loss)\n",
    "    \n",
    "    #Save initial parameters\n",
    "    save_params = save_params_dict(opt_pars=opt_pars, accuracy=accuracy, epoch=0 )\n",
    "    \n",
    "    #Initialise csv file\n",
    "    results_handle = open(results_filename, 'w')\n",
    "    results_writer=None\n",
    "    results_writer = csv.DictWriter(results_handle, fieldnames=save_params.keys())\n",
    "    results_writer.writeheader()\n",
    "    results_writer.writerow(save_params)\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        start_time = time.time()\n",
    "        epoch_loss = 0 \n",
    "           \n",
    "        #load next batch of data and convert\n",
    "        train_data = create_data(stimuli_pars, number = batch_size, offset = offset, ref_ori = ref_ori)\n",
    "\n",
    "        #Compute loss and gradient\n",
    "        epoch_loss, grad =jax.value_and_grad(loss)(opt_pars, ssn_pars, grid_pars, conn_pars, train_data, filter_pars,  conv_pars)\n",
    "\n",
    "        #Apply SGD through Adam optimizer per batch\n",
    "        updates, opt_state = optimizer.update(grad, opt_state)\n",
    "        opt_pars = optax.apply_updates(opt_pars, updates)\n",
    "        training_losses.append(epoch_loss)\n",
    "        \n",
    "        epoch_time = time.time() - start_time\n",
    "        print(opt_pars)\n",
    "\n",
    "        #Save the parameters given a number of epochs\n",
    "        if epoch in epochs_to_save:\n",
    "            \n",
    "            #Evaluate model \n",
    "            test_data = create_data(stimuli_pars, number = batch_size, offset = offset, ref_ori = ref_ori)\n",
    "            val_loss, accuracy, _= vmap_eval(opt_pars, ssn_pars, grid_pars, conn_pars, test_data, filter_pars,  conv_pars)\n",
    "            print('Training loss: {} ¦ Validation -- loss: {}, accuracy: {} at epoch {}, (time {})'.format(epoch_loss, val_loss, accuracy, epoch, epoch_time))\n",
    "            val_loss_per_epoch.append(val_loss)\n",
    "            \n",
    "            #Create dictionary of parameters to save\n",
    "            save_params = save_params_dict(opt_pars, accuracy, epoch)\n",
    "            \n",
    "            #Write results in csv file\n",
    "            results_writer.writerow(save_params)\n",
    "            \n",
    "            \n",
    "         \n",
    "    \n",
    "    #Reparametize parameters\n",
    "    signs=np.array([[1, -1], [1, -1]])    \n",
    "    opt_pars['logJ_2x2'] = np.exp(opt_pars['logJ_2x2'])*signs\n",
    "    opt_pars['logs_2x2'] = np.exp(opt_pars['logs_2x2'])\n",
    "    \n",
    "   \n",
    "    return opt_pars, val_loss_per_epoch, training_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7568a79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/d/temp/ssn_modelling/ssn-simulator/results/sima_test4.csv\n",
      "Before training  -- loss: 0.9340487718582153, accuracy: 0.2199999988079071 \n",
      "{'b_sig': DeviceArray(0.00099999, dtype=float32), 'c_E': DeviceArray(4.999, dtype=float32), 'c_I': DeviceArray(5.001, dtype=float32), 'logJ_2x2': DeviceArray([[1.4899517 , 0.5067398 ],\n",
      "             [1.6162026 , 0.21544056]], dtype=float32), 'logs_2x2': DeviceArray([[-1.6084379, -3.912023 ],\n",
      "             [-0.9172907, -3.912023 ]], dtype=float32), 'w_sig': DeviceArray([-0.04446743,  0.01270511, -0.1939411 , -0.26484513,\n",
      "             -0.00549892, -0.03229452,  0.05659591,  0.00737359,\n",
      "             -0.22383411,  0.13297245, -0.06788205,  0.0734621 ,\n",
      "              0.14930053,  0.16101134, -0.24490973,  0.11445116,\n",
      "             -0.42084718,  0.0074275 , -0.27646086, -0.011787  ,\n",
      "              0.17654273,  0.10219262,  0.03874103, -0.03846611,\n",
      "             -0.14198136], dtype=float32)}\n",
      "Training loss: 2519.15185546875 ¦ Validation -- loss: 0.939019501209259, accuracy: 0.10000000149011612 at epoch 1, (time 12.634104251861572)\n",
      "{'b_sig': DeviceArray(0.00194848, dtype=float32), 'c_E': DeviceArray(4.9980693, dtype=float32), 'c_I': DeviceArray(5.002001, dtype=float32), 'logJ_2x2': DeviceArray([[1.4889649 , 0.50772446],\n",
      "             [1.6171873 , 0.21445969]], dtype=float32), 'logs_2x2': DeviceArray([[-1.6074507, -3.912023 ],\n",
      "             [-0.9182647, -3.912023 ]], dtype=float32), 'w_sig': DeviceArray([-0.04415299,  0.01270511, -0.19451335, -0.26490098,\n",
      "             -0.00566769, -0.03311593,  0.05601596,  0.00665163,\n",
      "             -0.22383411,  0.13207975, -0.06742901,  0.07249073,\n",
      "              0.14829978,  0.1607708 , -0.24392407,  0.11543974,\n",
      "             -0.4212151 ,  0.00644695, -0.27556765, -0.01081146,\n",
      "              0.1755772 ,  0.10166931,  0.03973828, -0.03766347,\n",
      "             -0.14117871], dtype=float32)}\n",
      "{'b_sig': DeviceArray(0.00254656, dtype=float32), 'c_E': DeviceArray(4.9972754, dtype=float32), 'c_I': DeviceArray(5.0029945, dtype=float32), 'logJ_2x2': DeviceArray([[1.4879818 , 0.5087046 ],\n",
      "             [1.6181676 , 0.21348515]], dtype=float32), 'logs_2x2': DeviceArray([[-1.606473, -3.912023],\n",
      "             [-0.919235, -3.912023]], dtype=float32), 'w_sig': DeviceArray([-0.04348841,  0.01270511, -0.19477093, -0.26521254,\n",
      "             -0.00618251, -0.03335294,  0.05558713,  0.00695288,\n",
      "             -0.22383411,  0.13114052, -0.06726444,  0.0715156 ,\n",
      "              0.14754313,  0.16013405, -0.24298072,  0.11592124,\n",
      "             -0.42189884,  0.00546775, -0.2746651 , -0.00983396,\n",
      "              0.17462353,  0.10095738,  0.04071141, -0.03682784,\n",
      "             -0.14033091], dtype=float32)}\n",
      "Training loss: 2020.642822265625 ¦ Validation -- loss: 0.8487920761108398, accuracy: 0.3199999928474426 at epoch 3, (time 12.580661535263062)\n",
      "{'b_sig': DeviceArray(0.00307177, dtype=float32), 'c_E': DeviceArray(4.996436, dtype=float32), 'c_I': DeviceArray(5.0039835, dtype=float32), 'logJ_2x2': DeviceArray([[1.4870203 , 0.50965965],\n",
      "             [1.6191267 , 0.21254049]], dtype=float32), 'logs_2x2': DeviceArray([[-1.6055319 , -3.912023  ],\n",
      "             [-0.92015535, -3.912023  ]], dtype=float32), 'w_sig': DeviceArray([-0.04275614,  0.01270511, -0.19499817, -0.26537767,\n",
      "             -0.00631892, -0.03348628,  0.05517241,  0.00696247,\n",
      "             -0.22383411,  0.13023393, -0.06690768,  0.07055729,\n",
      "              0.14711946,  0.15975522, -0.24245168,  0.11635449,\n",
      "             -0.42198625,  0.00450698, -0.27372554, -0.00887671,\n",
      "              0.17370422,  0.10022375,  0.04167903, -0.0362384 ,\n",
      "             -0.13954099], dtype=float32)}\n",
      "{'b_sig': DeviceArray(0.00356592, dtype=float32), 'c_E': DeviceArray(4.995621, dtype=float32), 'c_I': DeviceArray(5.0049424, dtype=float32), 'logJ_2x2': DeviceArray([[1.4860729 , 0.51059747],\n",
      "             [1.6200699 , 0.21161708]], dtype=float32), 'logs_2x2': DeviceArray([[-1.6046046, -3.912023 ],\n",
      "             [-0.9210457, -3.912023 ]], dtype=float32), 'w_sig': DeviceArray([-0.04249656,  0.01270511, -0.19531615, -0.26582402,\n",
      "             -0.00666782, -0.03352969,  0.05455392,  0.00714773,\n",
      "             -0.22383411,  0.12932533, -0.06677094,  0.06960647,\n",
      "              0.1468232 ,  0.15928377, -0.24192278,  0.11673009,\n",
      "             -0.42181867,  0.00354113, -0.27282628, -0.00792782,\n",
      "              0.1728087 ,  0.09939815,  0.04262305, -0.0355422 ,\n",
      "             -0.13869993], dtype=float32)}\n",
      "Training loss: 1636.94189453125 ¦ Validation -- loss: 0.8472796678543091, accuracy: 0.30000001192092896 at epoch 5, (time 12.468375205993652)\n"
     ]
    }
   ],
   "source": [
    "print(results_filename)\n",
    "final_pars_test, val_loss_test, training_los_test= train_SSN_vmap(opt_pars, ssn_pars, grid_pars, conn_pars, stimuli_pars, filter_pars,  conv_pars, results_filename, epochs_to_save = epochs_to_save, ref_ori = 55, offset = 2, batch_size = 50, epochs = epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61be315e",
   "metadata": {},
   "source": [
    "## INITIALIZATION HISTOGRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2426c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import initial_acc\n",
    "all_acc, low_acc = initial_acc( opt_pars, ssn_pars, grid_pars, conn_pars, filter_pars,  conv_pars, stimuli_pars, jitter_max = 5,  std_max = 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a614a803",
   "metadata": {},
   "source": [
    "## PLOT RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ff3da7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(results_file, title=None):\n",
    "    \n",
    "    results = pd.read_csv(results_file, header = 0)\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12,8))\n",
    "\n",
    "    results.plot(x='epoch', y=[\"J_EE\", \"J_EI\", \"J_IE\", \"J_II\"], ax=axes[0,0])\n",
    "    results.plot(x='epoch', y=[\"s_EE\", \"s_EI\", \"s_IE\", \"s_II\"], ax = axes[0,1])\n",
    "    results.plot(x='epoch', y=[\"c_E\", \"c_I\"], ax = axes[1,0])\n",
    "    results.plot(x='epoch', y = 'val_accuracy', ax = axes[1,1])\n",
    "    \n",
    "    if title:\n",
    "        fig.suptitle(title)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0723dd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_ratios(results_file):\n",
    "    results = pd.read_csv(results_file, header = 0)\n",
    "    res = results.to_numpy()\n",
    "    Js=res[:,1:5]\n",
    "    ss = res[:,5:9]\n",
    "    #print(Js.type())\n",
    "    print(results.columns[1:5])\n",
    "    print(\"J ratios = \", np.array((Js[-1,:]/Js[0,:] -1)*100, dtype=int))\n",
    "    print(results.columns[5:9])\n",
    "    print(ss[-1,:]/ss[0,:])\n",
    "    print(\"s ratios = \", np.array((ss[-1,:]/ss[0,:] -1)*100, dtype=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6763b87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_filename = '/mnt/d/temp/ssn_modelling/ssn-simulator/results/constant_set_5.csv'\n",
    "results_filename2 = '/mnt/d/temp/ssn_modelling/ssn-simulator/results/constant_set_0.csv'\n",
    "results_filename3 = '/mnt/d/temp/ssn_modelling/ssn-simulator/results/constant_set_0_Tmax200.csv'\n",
    "results_filename4 = '/mnt/d/temp/ssn_modelling/ssn-simulator/results/constant_set_5_Tmax200.csv'\n",
    "results_new_loss='/mnt/d/temp/ssn_modelling/ssn-simulator/results/test_new_loss.csv'\n",
    "results_batch50 = '/mnt/d/temp/ssn_modelling/ssn-simulator/results/batch50_c_5_T400.csv'\n",
    "new_results = '/mnt/d/temp/ssn_modelling/ssn-simulator/results/batch50_c_0_T200.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a899f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['J_EE', 'J_EI', 'J_IE', 'J_II'], dtype='object')\n",
      "J ratios =  [0 0 0 0]\n",
      "Index(['s_EE', 's_EI', 's_IE', 's_II'], dtype='object')\n",
      "[1.0 1.0 1.0 1.0]\n",
      "s ratios =  [0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "param_ratios(results_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bf9436",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_ratios(results_batch50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4427ab04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_ratios(results_filename) #Tmax 400, constant 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8537ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_ratios(results_filename2)  #Tmax 400, constant 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8eaf822",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_ratios(results_filename3) #Tmax 200, constant 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44149fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_ratios(results_filename4) #Tmax 200, constant 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2a9ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_batch50='/mnt/d/temp/ssn_modelling/ssn-simulator/results/batch50_c_0_T200.csv'\n",
    "param_ratios(results_batch50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5040fdc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_results(results_batch50,  title='Tmax = 200, constant = 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9637eac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(results_filename2, title='Tmax = 400, constant = 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26830ef",
   "metadata": {},
   "source": [
    "## Proof of concept model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e60490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_log_J_2x2(Js0):\n",
    "    make_J2x2 = lambda Jee, Jei, Jie, Jii: np.array([[Jee, -Jei], [Jie,  -Jii]]) * np.pi * ssn_pars.psi\n",
    "    J_2x2 = make_J2x2(*Js0)\n",
    "    signs=np.array([[1, -1], [1, -1]])\n",
    "    logJ_2x2 =np.log(J_2x2*signs)\n",
    "    \n",
    "    return logJ_2x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ffef5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_pars(o_Js0, position, value, params):\n",
    "    \n",
    "    Js0 = o_Js0.copy()\n",
    "    Js0[position] = Js0[position]*value\n",
    "    #print(Js0[position])\n",
    "    updated_params = params.copy()\n",
    "    logJ_2x2 = make_log_J_2x2(Js0)\n",
    "    updated_params['logJ_2x2'] = logJ_2x2\n",
    "    \n",
    "    return updated_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06ead5a",
   "metadata": {},
   "source": [
    "1. Create results file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a287bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name of results csv\n",
    "home_dir = os.getcwd()\n",
    "#Create directory for results\n",
    "results_dir = os.path.join(home_dir, 'results')\n",
    "if os.path.exists(results_dir) == False:\n",
    "        os.makedirs(results_dir)\n",
    "        \n",
    "        \n",
    "results_name = 'proof.csv' #SPECIFY NAME OF RESULTS FILE\n",
    "if results_name == None:\n",
    "    results_name = 'results_test2.csv'\n",
    "\n",
    "results_filename = os.path.join(results_dir, results_name)\n",
    "results_handle = open(results_filename, 'w')\n",
    "\n",
    "#results_writer = csv.DictWriter(results_handle, fieldnames=save_params.keys())\n",
    "#results_writer.writeheader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e799487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_params(new_pars, test_accuracy, results_handle, header=False):\n",
    "    save_params= dict(val_accuracy= test_accuracy, \n",
    "    J_EE= new_pars['logJ_2x2'][0,0], J_EI = new_pars['logJ_2x2'][0,1], \n",
    "                  J_IE = new_pars['logJ_2x2'][1,0], J_II = new_pars['logJ_2x2'][1,1])\n",
    "    \n",
    "    if header==True:\n",
    "        results_writer = csv.DictWriter(results_handle, fieldnames=save_params.keys())\n",
    "        results_writer.writeheader()\n",
    "    \n",
    "    \n",
    "    results_writer.writerow(save_params)       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c582c9e",
   "metadata": {},
   "source": [
    "1. Redefine parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae4d43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caleb's params for the full (with local) model:\n",
    "o_Js0 = [1.82650658, 0.68194475, 2.06815311, 0.5106321]\n",
    "gE, gI = 0.57328625, 0.26144141\n",
    "\n",
    "sigEE, sigIE = 0.2, 0.40\n",
    "sigEI, sigII = .09, .09\n",
    "\n",
    "\n",
    "make_J2x2 = lambda Jee, Jei, Jie, Jii: np.array([[Jee, -Jei], [Jie,  -Jii]]) * np.pi * ssn_pars.psi\n",
    "J_2x2 = make_J2x2(*o_Js0)\n",
    "s_2x2 = np.array([[sigEE, sigEI],[sigIE, sigII]])\n",
    "\n",
    "#Positive reparameterization\n",
    "signs=np.array([[1, -1], [1, -1]])\n",
    "logJ_2x2 =np.log(J_2x2*signs)\n",
    "\n",
    "\n",
    "#Optimization pars\n",
    "opt_pars = dict(logJ_2x2 = logJ_2x2, logs_2x2 = logs_2x2, w_sig = w_sig, b_sig=b_sig, c_E = c_E, c_I = c_I)\n",
    "opt_pars['logJ_2x2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc9a182",
   "metadata": {},
   "source": [
    "2. Generate testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a2db89",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_ori = 55\n",
    "offset = 10\n",
    "batch_size = 200\n",
    "test_data = create_data(stimuli_pars, number = batch_size, offset = offset, ref_ori = ref_ori)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1156deb",
   "metadata": {},
   "source": [
    "3. Evaluate original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80297e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, test_accuracy, _ = vmap_eval(opt_pars, ssn_pars, grid_pars, conn_pars, test_data, filter_pars,  conv_pars)\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1065583b",
   "metadata": {},
   "source": [
    "--> Edit parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8501afac",
   "metadata": {},
   "source": [
    "J_EE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af97475",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pars = create_new_pars(o_Js0, 0, 0.8, opt_pars)\n",
    "_, test_accuracy, _ = vmap_eval(new_pars, ssn_pars, grid_pars, conn_pars, test_data, filter_pars,  conv_pars)\n",
    "print(test_accuracy)\n",
    "\n",
    "#save_params(new_pars, test_accuracy, results_handle, header = True)\n",
    "new_pars = create_new_pars(o_Js0, 0, 1.2, opt_pars)\n",
    "_, test_accuracy, _ = vmap_eval(new_pars, ssn_pars, grid_pars, conn_pars, test_data, filter_pars,  conv_pars)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435bf143",
   "metadata": {},
   "source": [
    "J_EI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52ebc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pars = create_new_pars(o_Js0, 1, 0.8, opt_pars)\n",
    "_, test_accuracy_1, _ = vmap_eval(new_pars, ssn_pars, grid_pars, conn_pars, test_data, filter_pars,  conv_pars)\n",
    "print(test_accuracy_1)\n",
    "\n",
    "new_pars = create_new_pars(o_Js0, 1, 1.2, opt_pars)\n",
    "_, test_accuracy_2, _ = vmap_eval(new_pars, ssn_pars, grid_pars, conn_pars, test_data, filter_pars,  conv_pars)\n",
    "print(test_accuracy_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fad2b2",
   "metadata": {},
   "source": [
    "J_IE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5feb9c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pars = create_new_pars(o_Js0, 2, 0.8, opt_pars)\n",
    "_, test_accuracy_1, _ = vmap_eval(new_pars, ssn_pars, grid_pars, conn_pars, test_data, filter_pars,  conv_pars)\n",
    "print(test_accuracy_1)\n",
    "\n",
    "new_pars = create_new_pars(o_Js0, 2, 1.2, opt_pars)\n",
    "_, test_accuracy_2, _ = vmap_eval(new_pars, ssn_pars, grid_pars, conn_pars, test_data, filter_pars,  conv_pars)\n",
    "print(test_accuracy_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac0c7f6",
   "metadata": {},
   "source": [
    "J_II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64bbc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pars = create_new_pars(o_Js0, 3, 0.8, opt_pars)\n",
    "_, test_accuracy_1, _ = vmap_eval(new_pars, ssn_pars, grid_pars, conn_pars, test_data, filter_pars,  conv_pars)\n",
    "print(test_accuracy_1)\n",
    "\n",
    "new_pars = create_new_pars(o_Js0, 3, 1.2, opt_pars)\n",
    "_, test_accuracy_2, _ = vmap_eval(new_pars, ssn_pars, grid_pars, conn_pars, test_data, filter_pars,  conv_pars)\n",
    "print(test_accuracy_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc95ad13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
